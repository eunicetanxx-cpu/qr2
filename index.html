<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>VI-Friendly Indoor Navigation (Color QR + Obstacle Alerts)</title>
  <style>
    :root{
      --bg:#000; --card:#111; --accent:#ffd54f; --accent-2:#00e676; --text:#fff;
      --btn-h:64px; --btn-font:22px;
    }
    /* High-contrast, large UI */
    html,body{height:100%; margin:0; background:var(--bg); color:var(--text); font-family: system-ui, -apple-system, "Segoe UI", Roboto, Arial; -webkit-font-smoothing:antialiased;}
    .app { max-width:980px; margin:12px auto; padding:16px; background:linear-gradient(180deg,#0b0b0b 0,#151515 100%); border-radius:12px; box-shadow:0 6px 20px rgba(0,0,0,0.6); }
    header { display:flex; gap:12px; align-items:center; }
    h1 { font-size:22px; margin:0; color:var(--accent); }
    .subtitle { color: #ddd; font-size:14px; margin-top:4px; }
    .controls { margin:14px 0; display:flex; gap:12px; flex-wrap:wrap; align-items:center; }
    .btn { background:var(--accent); color:#000; border:none; padding:12px 18px; border-radius:10px; font-size:var(--btn-font); height:var(--btn-h); min-width:160px; cursor:pointer; box-shadow:0 4px 12px rgba(0,0,0,0.6); }
    .btn.secondary { background:#222; color:var(--text); border:1px solid #333; }
    .btn.ghost { background:transparent; color:var(--accent); border:2px solid var(--accent); }
    .btn:focus { outline:3px solid #fff; outline-offset:2px; }
    .select { font-size:18px; padding:12px; border-radius:10px; height:var(--btn-h); background:#222; color:var(--text); border:1px solid #333; }
    .statusBox { margin-top:12px; padding:14px; background:#071018; border-radius:10px; border:1px solid #083; min-height:88px; }
    #overlayText { font-weight:700; font-size:20px; color:var(--text); margin-bottom:6px; }
    #srAnnounce { position:relative; font-size:18px; color:#fff; margin-top:6px; }
    #listeningBox { margin-top:10px; font-size:18px; color:#ffb74d; }
    .scan-progress { margin-top:10px; display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    .progress-pill { padding:10px 14px; border-radius:999px; background:#111; color:#ccc; font-size:18px; border:1px solid #222; min-width:200px; text-align:center; }
    .progress-pill.found { background:var(--accent-2); color:#000; font-weight:700; border:2px solid #003300; }
    /* Preview is small and not required for VI users but shown for sighted helpers */
    #preview { width:360px; height:180px; object-fit:cover; border-radius:8px; border:2px solid #222; display:block; margin-top:12px; }
    #controlsRow { display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    #log { margin-top:12px; background:#060606; color:#bbb; padding:10px; border-radius:8px; height:160px; overflow:auto; font-size:15px; border:1px solid #222; }
    .map-modal { position:fixed; inset:0; display:none; align-items:center; justify-content:center; background:rgba(0,0,0,0.75); z-index:999; }
    .map-modal .box { background:#111; padding:14px; max-width:900px; width:95%; max-height:85%; overflow:auto; border-radius:8px; border:2px solid #333; color:#fff; }
    #mapCanvas { width:100%; height:auto; border-radius:6px; background:#fff; }
    .visually-hidden { position:absolute !important; height:1px; width:1px; overflow:hidden; clip:rect(1px,1px,1px,1px); white-space:nowrap; }
    footer { margin-top:14px; color:#999; font-size:13px; }
    .help-block { margin-top:12px; background:#071; padding:10px; border-radius:8px; color:#001; font-weight:700; }
    /* make interactive elements large on small screens */
    @media (max-width:640px){
      .btn{ min-width:120px; font-size:20px; height:58px; }
      #preview{ width:100%; height:140px; }
    }
  </style>

  <!-- jsQR and OpenCV -->
  <script src="https://cdn.jsdelivr.net/npm/jsqr@1.4.0/dist/jsQR.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <!-- TensorFlow.js and COCO-SSD model for object detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <div class="app" role="application" aria-labelledby="appTitle">
    <header>
      <div>
        <h1 id="appTitle">VI Indoor Navigation</h1>
        <div class="subtitle">Color QR navigation • Voice input • Obstacle alerts</div>
      </div>
    </header>

    <div id="controlsRow" class="controls" role="region" aria-label="Main controls">
      <select id="colorFilter" class="select" aria-label="Filter QR color. Choose Any, Red, Green or Blue">
        <option>Any</option><option>Red</option><option>Green</option><option>Blue</option>
      </select>

      <button id="startBtn" class="btn" aria-pressed="false" aria-label="Start scanning for QR codes (S)">Start Scan</button>
      <button id="stopBtn" class="btn secondary" aria-pressed="false" aria-label="Stop scanning (Space)">Stop Scan</button>
      <button id="voiceDestBtn" class="btn ghost" aria-label="Voice destination input (V)">Voice Destination</button>
      <button id="mapBtn" class="btn secondary" aria-label="Show map (M)">Show Map</button>
      <button id="restartBtn" class="btn secondary" aria-label="Restart scanner (R)">Restart</button>

      <label style="display:flex; align-items:center; gap:8px; margin-left:6px; color:#ddd; font-size:16px;">
        <input type="checkbox" id="enableDetect" checked aria-label="Enable object detection"> Enable Object Detection
      </label>
    </div>

    <div class="statusBox" role="status" aria-live="polite">
      <div id="overlayText">Initializing — press Start Scan to begin.</div>
      <div id="srAnnounce" aria-live="polite" role="log">Status messages will be here for screen readers.</div>
      <div id="listeningBox" aria-hidden="true"></div>
      <div class="scan-progress" aria-hidden="false">
        <div id="progressRed" class="progress-pill" role="status">Red QR: Not found</div>
        <div id="progressGreen" class="progress-pill" role="status">Green QR: Not found</div>
        <div id="progressBlue" class="progress-pill" role="status">Blue QR: Not found</div>
      </div>
    </div>

    <!-- preview for sighted helpers / testing -->
    <img id="preview" alt="camera preview (for sighted assistants)" />

    <div id="log" aria-live="polite" role="log"></div>

    <div style="display:flex; gap:12px; margin-top:12px; align-items:center;">
      <div style="flex:1;">
        <div class="help-block">Quick tips: Press <strong>S</strong> to Start, <strong>V</strong> for Voice input, <strong>Space</strong> to Stop. For best results use a quiet environment and point camera at QR codes.</div>
      </div>
    </div>

    <div class="map-modal" id="mapModal" role="dialog" aria-modal="true" aria-labelledby="mapTitle">
      <div class="box">
        <h3 id="mapTitle">Map Preview</h3>
        <canvas id="mapCanvas" width="900" height="600"></canvas>
        <div style="text-align:right; margin-top:8px;">
          <button id="closeMap" class="btn secondary" aria-label="Close map">Close</button>
        </div>
      </div>
    </div>

    <footer>Built for visually impaired users — spoken prompts and vibration give guidance.</footer>
  </div>

<script>
/* ======= Accessible announce wrapper ======= */
const overlayText = document.getElementById('overlayText');
const srAnnounce = document.getElementById('srAnnounce');
function announce(text, interrupt=false) {
  // Update visible status
  overlayText.textContent = text;
  // Update screen-reader region (polite)
  srAnnounce.textContent = text;
  // Use TTS via TTS manager (keeps queue, no overlap)
  TTS.speak(text, interrupt);
  log(`[ANNOUNCE] ${text}`);
}

/* ======= UI elements ======= */
const video = document.createElement('video');
video.setAttribute('id','video'); video.setAttribute('autoplay',''); video.setAttribute('playsinline','');
video.style.display = 'none';
document.body.appendChild(video);

const canvasDisp = document.createElement('canvas');
canvasDisp.setAttribute('id','canvasDisp');
canvasDisp.style.display = 'none';
document.body.appendChild(canvasDisp);

const ctxDisp = canvasDisp.getContext('2d', { willReadFrequently: true });
const preview = document.getElementById('preview');
const resultEl = document.getElementById('result');
const logEl = document.getElementById('log');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const voiceDestBtn = document.getElementById('voiceDestBtn');
const colorFilterEl = document.getElementById('colorFilter');
const mapBtn = document.getElementById('mapBtn');
const mapModal = document.getElementById('mapModal');
const mapCanvas = document.getElementById('mapCanvas');
const closeMap = document.getElementById('closeMap');
const restartBtn = document.getElementById('restartBtn');
const progressRed = document.getElementById('progressRed');
const progressGreen = document.getElementById('progressGreen');
const progressBlue = document.getElementById('progressBlue');
const enableDetectCheckbox = document.getElementById('enableDetect');

const log = (m) => { console.log(m); const t = new Date().toLocaleTimeString(); logEl.innerText += `[${t}] ${m}\n`; logEl.scrollTop = logEl.scrollHeight; };

/* ======= Config & state ======= */
const SCAN_SIZE = 300;
let scanBox = { x: 0, y: 0, size: SCAN_SIZE };
let cvReady = false;
let animationFrameId = null;
let stream = null;
let scannerRunning = false;
let foundResults = new Map();
let scanStartTime = Date.now();
let currentLocation = null;
let currentNavigationTarget = null;
let latestDetections = [];
let actionsTriggered = false;

/* ======= Object detection globals ======= */
let cocoModel = null;
let cocoReady = false;
const DETECTION_INTERVAL_MS = 900;
const SCORE_THRESHOLD = 0.45;
const CENTER_TOLERANCE = 0.25;
const DISTANCE_ESTIMATE_SCALE = 1.6;
let lastDetectTime = 0;
const alertCooldown = 3000;
const lastAlertAt = {};
const HARMFUL_CLASSES = new Set(['person','chair','couch','bench','dining table','stop sign','tv','suitcase','backpack','bed','toilet']);

/* ======= User gesture tracking for SR on some browsers ======= */
let userGesturePerformed = false;

/* ======= Graph & navigation (unchanged) ======= */
/* (Copy your node_coords, graph_raw, add_bidirectional_edges, dijkstra, MinHeap, direction helpers) */
const node_coords = {
  "Female Toilet (NGT1)": [2009, 1357],
  "Male Toilet (NGT2)": [1955, 1357],
  "N001 (backdoor)": [2100, 1135],
  "N001": [1907, 1121],
  "N002": [1651, 1097],
  "N003": [1387, 1074],
  "N004": [892, 1097],
  "N005": [638, 1115],
  "N006": [383, 1139],
  "N007": [127, 1158],
  "N008": [4, 1330],
  "Female Toilet (NGT5)": [357, 1350],
  "Male Toilet (NGT4)": [403, 1351],
  "N009": [492, 1330],
  "N010": [822, 1335],
  "N011": [1251, 1340],
  "N012": [1597, 1340],
};

const graph_raw = {
  "Female Toilet (NGT1)": {"Male Toilet (NGT2)": 1.89},
  "N001": {"Female Toilet (NGT1)": 9.00, "N001 (backdoor)": 6.77, "N002": 9.00},
  "N002": {"N003": 9.28},
  "N003": {"N004": 17.35},
  "N004": {"N005": 8.91},
  "N005": {"N006": 8.97},
  "N006": {"Male Toilet (NGT4)": 7.45, "Female Toilet (NGT5)": 7.44, "N007": 8.99},
  "N007": {"N008": 7.40},
  "N008": {"Female Toilet (NGT5)": 12.38},
  "Female Toilet (NGT5)": {"Male Toilet (NGT4)": 1.61},
  "Male Toilet (NGT4)": {"N009": 3.20},
  "N009": {"N010": 11.55},
  "N010": {"N011": 15.02},
  "N011": {"N012": 12.11},
  "N012": {"Male Toilet (NGT2)": 12.55}
};
function add_bidirectional_edges(graph_in) {
  const new_graph = {};
  for (const k in graph_in) new_graph[k] = {};
  for (const from in graph_in) {
    for (const to in graph_in[from]) {
      const w = graph_in[from][to];
      new_graph[from][to] = w;
      if (!new_graph[to]) new_graph[to] = {};
      new_graph[to][from] = w;
    }
  }
  return new_graph;
}
const graph = add_bidirectional_edges(graph_raw);

function dijkstra(gr, start, end) {
  const pq = new MinHeap();
  pq.push({cost:0,node:start,path:[]});
  const visited = new Set();
  while (!pq.empty()) {
    const item = pq.pop();
    const {cost, node, path} = item;
    if (visited.has(node)) continue;
    const newPath = path.concat([node]);
    visited.add(node);
    if (node === end) return {path:newPath, cost};
    const neighbors = gr[node] || {};
    for (const nb in neighbors) {
      if (!visited.has(nb)) pq.push({cost: cost + neighbors[nb], node: nb, path: newPath});
    }
  }
  return {path:[], cost: Infinity};
}
class MinHeap {
  constructor(){ this.a = []; }
  push(x){ this.a.push(x); this._siftUp(); }
  pop(){ if(this.a.length===0) return null; const r=this.a[0]; const last=this.a.pop(); if(this.a.length) { this.a[0]=last; this._siftDown(); } return r; }
  empty(){ return this.a.length===0; }
  _siftUp(){ let i=this.a.length-1; while(i>0){ let p=Math.floor((i-1)/2); if(this.a[p].cost<=this.a[i].cost) break; [this.a[p],this.a[i]]=[this.a[i],this.a[p]]; i=p; } }
  _siftDown(){ let i=0; const n=this.a.length; while(true){ let l=i*2+1; let r=i*2+2; let smallest=i; if(l<n && this.a[l].cost < this.a[smallest].cost) smallest=l; if(r<n && this.a[r].cost < this.a[smallest].cost) smallest=r; if(smallest===i) break; [this.a[i],this.a[smallest]]=[this.a[smallest],this.a[i]]; i=smallest; } }
}
function get_turn_direction(p1,p2,p3) {
  const v1 = [p2[0]-p1[0], p2[1]-p1[1]];
  const v2 = [p3[0]-p2[0], p3[1]-p2[1]];
  const raw = (Math.atan2(v2[1], v2[0]) - Math.atan2(v1[1], v1[0])) * 180/Math.PI;
  const angle = (raw + 360) % 360;
  if (angle < 45 || angle > 315) return "Move straight";
  if (angle >= 45 && angle < 135) return "Turn right";
  if (angle >= 135 && angle < 225) return "Turn back";
  return "Turn left";
}
function get_initial_direction_simple(p1,p2) {
  const dx = p2[0]-p1[0], dy = p2[1]-p1[1];
  const angle = (Math.atan2(dy,dx) * 180/Math.PI + 360) % 360;
  if (angle >= 315 || angle < 45) return "Move straight";
  if (angle >= 45 && angle < 135) return "Turn right";
  if (angle >= 135 && angle < 225) return "Turn back";
  return "Turn left";
}

/* ======= TTS manager (keeps queue; prevents overlap) ======= */
const TTS = {
  queue: [],
  speaking: false,
  speak(text, interrupt=false) {
    if (!text) return;
    if (interrupt) {
      this.queue = [];
      if (speechSynthesis.speaking) speechSynthesis.cancel();
    }
    this.queue.push(text);
    this._maybeSpeak();
  },
  _maybeSpeak() {
    if (this.speaking) return;
    const next = this.queue.shift();
    if (!next) return;
    this.speaking = true;
    const utt = new SpeechSynthesisUtterance(next);
    utt.rate = 1.0;
    utt.onend = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    utt.onerror = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    speechSynthesis.speak(utt);
  }
};

/* ======= Speech recognition availability ======= */
let SR_AVAILABLE = false;
try {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (SpeechRecognition) SR_AVAILABLE = true;
} catch(e){ SR_AVAILABLE=false; }

/* ======= Color detection functions (use same implementations) ======= */
/* ... include createColorMask, extractColorChannel, enhanceBlueContrast, detectWithOpenCV, detect_colored_qr_in_frame_js - unchanged from your previous implementations ... */

/* For readability in this response I will re-insert the functions unchanged. In your file keep these exact functions. */

function createColorMask(imageData, color) {
  const data = imageData.data;
  const maskData = new Uint8ClampedArray(data.length);
  let colorPixels = 0;
  let totalPixels = data.length / 4;
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i];
    const g = data[i + 1];
    const b = data[i + 2];
    let isTargetColor = false;
    if (color === 'red') {
      isTargetColor = (r > g + 30 && r > b + 30 && r > 80) || 
                     (r > 150 && r > g * 1.5 && r > b * 1.5) ||
                     (r > 120 && g < 80 && b < 80);
    } else if (color === 'green') {
      isTargetColor = (g > r + 30 && g > b + 30 && g > 80) || 
                     (g > 150 && g > r * 1.5 && g > b * 1.5) ||
                     (g > 120 && r < 80 && b < 80);
    } else if (color === 'blue') {
      isTargetColor = (b > r + 15 && b > g + 15 && b > 50) || 
                     (b > 100 && b > r * 1.1 && b > g * 1.1) ||
                     (b > 70 && r < 120 && g < 120) ||
                     (b > 60 && b > r && b > g && (r + g) < b * 1.5) ||
                     (b > 40 && b > r * 1.2 && b > g * 1.2 && r < 100 && g < 100);
    }
    if (isTargetColor) {
      colorPixels++;
      maskData[i] = 255; maskData[i + 1] = 255; maskData[i + 2] = 255; maskData[i + 3] = 255;
    } else {
      maskData[i] = 0; maskData[i + 1] = 0; maskData[i + 2] = 0; maskData[i + 3] = 255;
    }
  }
  const colorRatio = colorPixels / totalPixels;
  if (colorRatio > 0.01) {
    console.log(`${color} mask: ${colorPixels}/${totalPixels} pixels (${(colorRatio*100).toFixed(1)}%)`);
  }
  return new ImageData(maskData, imageData.width, imageData.height);
}

function extractColorChannel(imageData, channel) {
  const data = new Uint8ClampedArray(imageData.data);
  let colorPixels = 0;
  let totalPixels = data.length / 4;
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i], g = data[i + 1], b = data[i + 2];
    let intensity;
    let isColorDominant = false;
    if (channel === 'red') {
      intensity = r;
      isColorDominant = (r > g && r > b && r > 50);
      if (isColorDominant) colorPixels++;
    } else if (channel === 'green') {
      intensity = g;
      isColorDominant = (g > r && g > b && g > 50);
      if (isColorDominant) colorPixels++;
    } else if (channel === 'blue') {
      intensity = b;
      isColorDominant = (b > r && b > g && b > 30) || 
                       (b > 60 && b > r * 1.1 && b > g * 1.1) ||
                       (b > 40 && r < 100 && g < 100);
      if (isColorDominant) {
        colorPixels++;
        intensity = Math.min(255, b * 1.8);
      }
    }
    data[i] = intensity; data[i + 1] = intensity; data[i + 2] = intensity;
  }
  if (channel === 'blue') {
    const colorRatio = colorPixels / totalPixels;
    if (colorRatio > 0.005) {
      console.log(`Blue channel enhanced: ${colorPixels}/${totalPixels} pixels (${(colorRatio*100).toFixed(2)}%)`);
    }
  }
  return new ImageData(data, imageData.width, imageData.height);
}

function enhanceBlueContrast(imageData) {
  const data = new Uint8ClampedArray(imageData.data);
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i], g = data[i + 1], b = data[i + 2];
    let blueIntensity = 0;
    if (b > r && b > g) {
      blueIntensity = Math.min(255, b * 2);
    } else if (b > 60 && (b - r > 10 || b - g > 10)) {
      blueIntensity = Math.min(255, b * 1.5);
    } else if (b > 40 && r < 100 && g < 100) {
      blueIntensity = Math.min(255, b * 1.8);
    } else {
      blueIntensity = Math.max(0, Math.min(r, g, b) * 0.3);
    }
    data[i] = blueIntensity; data[i + 1] = blueIntensity; data[i + 2] = blueIntensity;
  }
  return new ImageData(data, imageData.width, imageData.height);
}

function detectWithOpenCV(imageData, color) {
  if (!cvReady) return null;
  try {
    const src = cv.matFromImageData(imageData);
    let hsv = new cv.Mat();
    cv.cvtColor(src, hsv, cv.COLOR_RGBA2RGB);
    cv.cvtColor(hsv, hsv, cv.COLOR_RGB2HSV);
    let mask = new cv.Mat();
    let low, high;
    if (color === 'red') {
      let mask1 = new cv.Mat(), mask2 = new cv.Mat();
      low = new cv.Scalar(0, 40, 40); high = new cv.Scalar(10, 255, 255); cv.inRange(hsv, low, high, mask1);
      low = new cv.Scalar(170, 40, 40); high = new cv.Scalar(180, 255, 255); cv.inRange(hsv, low, high, mask2);
      cv.add(mask1, mask2, mask); mask1.delete(); mask2.delete();
    } else if (color === 'green') {
      low = new cv.Scalar(35, 30, 30); high = new cv.Scalar(85, 255, 255); cv.inRange(hsv, low, high, mask);
    } else if (color === 'blue') {
      let mask1 = new cv.Mat(), mask2 = new cv.Mat(), mask3 = new cv.Mat();
      low = new cv.Scalar(100, 25, 25); high = new cv.Scalar(130, 255, 255); cv.inRange(hsv, low, high, mask1);
      low = new cv.Scalar(90, 20, 20); high = new cv.Scalar(140, 255, 255); cv.inRange(hsv, low, high, mask2);
      low = new cv.Scalar(105, 15, 30); high = new cv.Scalar(125, 255, 255); cv.inRange(hsv, low, high, mask3);
      cv.add(mask1, mask2, mask); cv.add(mask, mask3, mask); mask1.delete(); mask2.delete(); mask3.delete();
    }
    let kernel3 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3));
    let kernel5 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
    cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel3);
    cv.morphologyEx(mask, mask, cv.MORPH_CLOSE, kernel5);
    cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel3);
    kernel3.delete(); kernel5.delete();
    let rgba = new cv.Mat();
    cv.cvtColor(mask, rgba, cv.COLOR_GRAY2RGBA);
    const result = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
    src.delete(); hsv.delete(); mask.delete(); rgba.delete();
    return result;
  } catch(e) {
    console.error('OpenCV detection error:', e);
    return null;
  }
}

function detect_colored_qr_in_frame_js(imageData, targetColor=null) {
  const COLORS = ['red', 'green', 'blue'];
  for (const color of COLORS) {
    if (targetColor && color !== targetColor) continue;
    try {
      const chImg = extractColorChannel(imageData, color);
      const code = jsQR(chImg.data, chImg.width, chImg.height, { inversionAttempts: 'attemptBoth' });
      if (code && code.data) {
        let boxArea = null;
        if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
          const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
          const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
          boxArea = Math.abs(w*h);
        }
        return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Enhanced-Channel', location: code.location || null, boxArea };
      }
    } catch(e) { console.warn('Enhanced channel decode error', color, e); }
    if (color === 'blue') {
      try {
        const maskImg = createColorMask(imageData, color);
        const code = jsQR(maskImg.data, maskImg.width, maskImg.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          let boxArea = null;
          if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
            const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
            const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
            boxArea = Math.abs(w*h);
          }
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Color-Mask', location: code.location || null, boxArea };
        }
      } catch(e) { console.warn('Color mask decode error', color, e); }
    }
    if (cvReady) {
      try {
        const cvProcessed = detectWithOpenCV(imageData, color);
        if (cvProcessed) {
          const code = jsQR(cvProcessed.data, cvProcessed.width, cvProcessed.height, { inversionAttempts: 'attemptBoth' });
          if (code && code.data) {
            let boxArea = null;
            if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
              const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
              const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
              boxArea = Math.abs(w*h);
            }
            return { found: true, decoded: code.data.trim(), colorFound: color, method: 'OpenCV-HSV', location: code.location || null, boxArea };
          }
        }
      } catch(e) { console.warn('OpenCV approach failed for', color, e); }
    }
    if (color === 'blue') {
      try {
        const enhanced = enhanceBlueContrast(imageData);
        const code = jsQR(enhanced.data, enhanced.width, enhanced.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          let boxArea = null;
          if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
            const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
            const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
            boxArea = Math.abs(w*h);
          }
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Blue-Enhanced', location: code.location || null, boxArea };
        }
      } catch(e) { console.warn('Blue enhancement failed', e); }
    }
  }
  return { found: false };
}

/* ======= Progress UI update (also announce for VI) ======= */
function updateProgressDisplay() {
  const colors = ['red','green','blue'];
  colors.forEach(color => {
    const el = color === 'red' ? progressRed : color === 'green' ? progressGreen : progressBlue;
    if (foundResults.has(color)) {
      el.classList.add('found');
      el.textContent = `${color.toUpperCase()} QR: ${foundResults.get(color).decoded}`;
    } else {
      el.classList.remove('found');
      el.textContent = `${color.charAt(0).toUpperCase() + color.slice(1)} QR: Scanning...`;
    }
  });
  // Announce progress summary in a concise form
  const foundCount = foundResults.size;
  announce(`${foundCount} of 3 QR codes found.`, false);
}

/* ======= Vibration helpers for VI users ======= */
let lastVibrateAt = 0;
function vibrateProximityFromRatio(ratio) {
  if (!('vibrate' in navigator)) return;
  const now = Date.now();
  if (now - lastVibrateAt < 160) return;
  lastVibrateAt = now;
  const intensity = Math.min(1, Math.max(0, (ratio - 0.02) / 0.6));
  const dur = Math.round(40 + intensity * 280);
  const pattern = [dur, 40];
  try { navigator.vibrate(pattern); } catch(e){}
}
function vibrateApproachPattern(ratio) {
  if (!('vibrate' in navigator)) return;
  if (ratio < 0.12) return;
  const norm = Math.min(1, Math.max(0, (ratio - 0.12) / 0.68));
  const pulses = 2 + Math.round(norm * 6);
  const strongMs = 60 + Math.round(norm * 220);
  const gapMs = 40;
  const pattern = [];
  for (let i=0;i<pulses;i++){ pattern.push(strongMs); if(i < pulses-1) pattern.push(gapMs); }
  try { navigator.vibrate(pattern); } catch(e){}
}
function vibrateArrival() {
  if (!('vibrate' in navigator)) return;
  try { navigator.vibrate([80,40,80,40,120]); } catch(e){}
}

/* ======= Camera start/stop ======= */
async function startCamera() {
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } }, audio: false
    });
    video.srcObject = stream;
    await video.play();
    canvasDisp.width = video.videoWidth; canvasDisp.height = video.videoHeight;
    preview.width = Math.min(820, video.videoWidth);
    preview.height = Math.min(360, video.videoHeight);
    scanBox.x = Math.floor((canvasDisp.width - SCAN_SIZE)/2);
    scanBox.y = Math.floor((canvasDisp.height - SCAN_SIZE)/2);
    scanStartTime = Date.now();
    foundResults.clear();
    actionsTriggered = false;
    scannerRunning = true;
    userGesturePerformed = true;
    announce("Camera started. Scanning for QR codes. Point phone camera at QR codes.", true);
    updateProgressDisplay();
    processFrame();
    startBtn.setAttribute('aria-pressed','true');
    return true;
  } catch(e) {
    announce("Camera access denied or unavailable. Check permissions and try again.", true);
    log("Camera error: " + e);
    return false;
  }
}
function stopCamera() {
  if (stream) stream.getTracks().forEach(t => t.stop());
  if (animationFrameId) { cancelAnimationFrame(animationFrameId); animationFrameId = null; }
  scannerRunning = false;
  announce("Scanner stopped.", true);
  startBtn.setAttribute('aria-pressed','false');
  log("Camera stopped.");
}

/* ======= Load COCO-SSD model ======= */
async function loadCocoModel() {
  try {
    announce("Loading object detection model. This may take a moment.", false);
    log("Loading coco-ssd...");
    cocoModel = await cocoSsd.load();
    cocoReady = true;
    announce("Object detection ready.", false);
    log("coco-ssd loaded");
  } catch(e) {
    cocoReady = false;
    log("coco load failed: " + e);
    announce("Object detection failed to load.", false);
  }
}
loadCocoModel();

/* ======= Speech recognition helper with interim updates ======= */
function startSpeechRecognition({lang='en-US', interim=true, timeout=9000, onInterim=null} = {}) {
  return new Promise((resolve) => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) { resolve(null); return; }
    let recognition;
    try { recognition = new SR(); } catch(e) { resolve(null); return; }
    recognition.lang = lang; recognition.interimResults = interim; recognition.maxAlternatives = 3;
    let finalTranscript = '';
    let resolved = false;
    const timer = setTimeout(() => {
      if (!resolved) { resolved = true; try { recognition.stop(); } catch(e){}; resolve(null); }
    }, timeout);
    recognition.onresult = (evt) => {
      const results = Array.from(evt.results);
      const interimText = results.map(r => r[0].transcript).join(' ');
      // Call interim callback to show listening text
      if (onInterim) onInterim(interimText);
      for (const r of results) { if (r.isFinal) finalTranscript = r[0].transcript; }
      if (finalTranscript && !resolved) { resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(e){}; resolve(finalTranscript.trim()); }
    };
    recognition.onend = () => {
      if (resolved) return;
      resolved = true; clearTimeout(timer); resolve(finalTranscript ? finalTranscript.trim() : null);
    };
    recognition.onerror = (e) => {
      if (resolved) return;
      resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(err){}; resolve(null);
    };
    try { recognition.start(); } catch(e) { clearTimeout(timer); resolve(null); }
  });
}

/* ======= Processing loop (QR + Object detection) ======= */
let qrDecoderBusy = false;
let frameSkipCounter = 0;

async function processFrame(){
  if (!scannerRunning) return;
  animationFrameId = requestAnimationFrame(processFrame);
  if (!video || video.readyState < 2) return;
  frameSkipCounter++;
  if (frameSkipCounter % 3 !== 0 && foundResults.size < 3) return;
  try {
    ctxDisp.drawImage(video, 0, 0, canvasDisp.width, canvasDisp.height);
    // update preview occasionally
    if (frameSkipCounter % 6 === 0) {
      try {
        const tmp = document.createElement('canvas');
        tmp.width = canvasDisp.width; tmp.height = canvasDisp.height;
        const tmpCtx = tmp.getContext('2d');
        tmpCtx.drawImage(canvasDisp, 0, 0);
        // draw scan rect for sighted helper
        tmpCtx.strokeStyle = '#00ff00'; tmpCtx.lineWidth = 3;
        tmpCtx.strokeRect(scanBox.x, scanBox.y, scanBox.size, scanBox.size);
        preview.src = tmp.toDataURL('image/png');
      } catch(e){}
    }

    if (qrDecoderBusy) return;
    qrDecoderBusy = true;
    setTimeout(async () => {
      try {
        const imageData = ctxDisp.getImageData(scanBox.x, scanBox.y, scanBox.size, scanBox.size);
        const targetFilter = (colorFilterEl.value === "Any") ? null : colorFilterEl.value.toLowerCase();
        const colorOrder = targetFilter ? [targetFilter] : ['blue','red','green'];
        for (const color of colorOrder) {
          if (foundResults.has(color)) continue;
          const detection = detect_colored_qr_in_frame_js(imageData, color);
          if (detection.found && detection.decoded) {
            const decodedClean = detection.decoded.trim();
            foundResults.set(color, { decoded: decodedClean, method: detection.method || 'unknown', boxArea: detection.boxArea || null });
            announce(`${color} QR found: ${decodedClean}`, true);
            updateProgressDisplay();
            if (detection.boxArea) {
              const scanArea = scanBox.size * scanBox.size;
              const ratio = detection.boxArea / scanArea;
              vibrateProximityFromRatio(ratio);
              if (ratio >= 0.15) vibrateApproachPattern(ratio);
            }
            // immediately handle decoded to update navigation state
            handleDecoded(decodedClean, color);
            break;
          }
        }

        const allColors = ['red','green','blue'];
        const foundColors = Array.from(foundResults.keys());
        if (!actionsTriggered && allColors.every(c => foundColors.includes(c))) {
          triggerAllActionsOnce();
        }

        // Object detection (periodic)
        const now = performance.now();
        if (enableDetectCheckbox.checked && cocoReady && (now - lastDetectTime > DETECTION_INTERVAL_MS)) {
          lastDetectTime = now;
          try {
            const off = document.createElement('canvas');
            const D_W = 480;
            const scale = D_W / canvasDisp.width;
            off.width = D_W; off.height = Math.floor(canvasDisp.height * scale);
            const offCtx = off.getContext('2d');
            offCtx.drawImage(canvasDisp, 0, 0, off.width, off.height);
            const predictions = await cocoModel.detect(off);
            const preds = predictions.filter(p => p.score >= SCORE_THRESHOLD);
            const scaleBack = canvasDisp.width / off.width;
            latestDetections = preds.map(p => {
              const [x,y,w,h] = p.bbox;
              return { class: p.class, score: p.score, bbox: [x*scaleBack, y*scaleBack, w*scaleBack, h*scaleBack] };
            });

            // choose harmful candidate
            let candidate = null;
            const fh = canvasDisp.height;
            const fw = canvasDisp.width;
            for (const det of latestDetections) {
              if (!HARMFUL_CLASSES.has(det.class)) continue;
              const [x,y,w,h] = det.bbox;
              const cx = x + w/2;
              const centerDelta = Math.abs(cx - fw/2) / fw;
              const score = (h / fh) * (1.0 - Math.min(centerDelta / 0.5, 1.0));
              if (!candidate || score > candidate.score) candidate = {det, score};
            }
            if (candidate) {
              const det = candidate.det;
              const [x,y,w,h] = det.bbox;
              const cx = x + w/2;
              const centerDelta = Math.abs(cx - fw/2) / fw;
              const isAhead = (centerDelta <= CENTER_TOLERANCE) && (h / fh >= 0.06);
              if (isAhead) {
                const cls = det.class;
                const nowTs = Date.now();
                if (!lastAlertAt[cls] || (nowTs - lastAlertAt[cls] > alertCooldown)) {
                  const ratio = (h / fh);
                  let distMeters = (DISTANCE_ESTIMATE_SCALE / Math.max(ratio, 0.02));
                  distMeters = Math.min(Math.max(distMeters, 0.2), 50.0);
                  if (distMeters <= 5.0) {
                    announce(`Obstacle ahead: ${cls}, approximately ${distMeters.toFixed(1)} meters.`, false);
                    lastAlertAt[cls] = nowTs;
                    log(`[OBSTACLE] ${cls} @ ${distMeters.toFixed(1)}m`);
                  } else {
                    log(`[OBSTACLE] ${cls} detected but ${distMeters.toFixed(1)}m away (>5m) - no alert`);
                  }
                }
              }
            }
          } catch(e) {
            console.warn("Object detection error:", e);
          }
        }

      } catch(e) {
        console.error("Frame processing error:", e);
      } finally {
        qrDecoderBusy = false;
      }
    }, 40);
  } catch(e){}
}

/* ======= Trigger after 3 QRs found (improved announcements) ======= */
function triggerAllActionsOnce(){
  if (actionsTriggered) return;
  actionsTriggered = true;
  log("All three color QR codes detected");
  announce("All QR codes detected. Processing information now.", true);
  const greenQR = foundResults.get('green')?.decoded || '';
  const blueQR = foundResults.get('blue')?.decoded || '';  
  const redQR = foundResults.get('red')?.decoded || '';
  stopCamera();
  setTimeout(()=>{ log("Map info: " + greenQR); announce("Map information available.", false); drawMap(); mapModal.style.display = 'flex'; }, 700);
  setTimeout(()=>{ log("Accessibility: " + blueQR); announce("Accessibility information: " + blueQR, false); }, 1500);
  setTimeout(()=>{ currentLocation = redQR; log("Current location: " + redQR); announce("Your current location is " + redQR, false); }, 2500);
  setTimeout(()=>{ if (SR_AVAILABLE) { announce("Please press Voice button and speak destination when ready.", false); } else { show_destination_modal(); } }, 3500);
}

/* ======= Destination selection & voice handling (robust loop) ======= */
function show_destination_modal() {
  if (!currentLocation) { alert("No current location detected. Please scan QR codes first."); return; }
  const candidates = Object.keys(node_coords).filter(n => n !== currentLocation);
  const candidateList = candidates.map((p,i)=>`${i+1}. ${p}`).join('\n');
  announce("Opening text selection. Check the screen for options.", false);
  const dest = prompt(`Current: ${currentLocation}\nAvailable:\n${candidateList}\n\nType name or number:`);
  if (!dest) { announce("No destination selected.", false); return; }
  let destination = dest.trim();
  const destNumber = parseInt(destination);
  if (!isNaN(destNumber) && destNumber >=1 && destNumber <= candidates.length) {
    destination = candidates[destNumber-1];
  } else {
    const best = findBestLocationMatch(destination, candidates);
    if (best) destination = best;
    else { announce("Destination not found. Please try voice input.", false); setTimeout(()=>ask_destination_via_voice(), 600); return; }
  }
  announce(`You selected ${destination}. Confirming.`, false);
  if (confirm(`Navigate to: ${destination}?`)) start_navigation(destination);
  else { announce("Selection cancelled. Try again.", false); setTimeout(()=>show_destination_modal(), 500); }
}

function findBestLocationMatch(input, candidates) {
  const s = input.toLowerCase().trim();
  let m = candidates.find(c=>c.toLowerCase()===s);
  if (m) return m;
  m = candidates.find(c=>c.toLowerCase().includes(s));
  if (m) return m;
  m = candidates.find(c=>c.toLowerCase().split(' ').some(word => s.includes(word) || word.includes(s)));
  if (m) return m;
  return null;
}

async function ask_destination_via_voice(){
  if (!currentLocation) { announce("No current location. Scan first.", false); return; }
  if (!SR_AVAILABLE) { announce("Speech recognition not available. Please use text input.", false); show_destination_modal(); return; }
  if (!userGesturePerformed) { announce("To use voice input, please press the Voice Destination button now.", false); return; }

  let tries = 0;
  while (tries < 5) {
    tries++;
    announce("Please say your destination after the beep.", true);
    await new Promise(r=>setTimeout(r,700));
    const interimBox = document.getElementById('listeningBox');
    interimBox.style.display = 'block'; interimBox.textContent = "Listening… (speak now)";
    const transcript = await startSpeechRecognition({lang:'en-US', interim:true, timeout:9000, onInterim:(t)=>{ interimBox.textContent = "Listening… " + t; }});
    interimBox.textContent = '';
    if (!transcript) {
      log("No transcript");
      announce("I didn't catch that. Let's try again.", false);
      continue;
    }
    log("Recognized: " + transcript);
    const candidates = Object.keys(node_coords).filter(n => n !== currentLocation);
    const bestMatch = findBestLocationMatch(transcript, candidates);
    if (!bestMatch) { announce("I couldn't find that location. Please say your destination again.", false); continue; }

    announce(`Did you mean ${bestMatch}? Say yes or no.`, false);
    await new Promise(r=>setTimeout(r,600));
    const conf = await startSpeechRecognition({lang:'en-US', interim:false, timeout:6000});
    if (!conf) {
      const ok = confirm(`Did you mean ${bestMatch}? Press OK for yes.`);
      if (ok) { start_navigation(bestMatch); return; }
      else { announce("Okay, let's try again.", false); continue; }
    }
    const settled = conf.toLowerCase();
    log("Confirmation: " + settled);
    if (settled.includes('yes') || settled.includes('yeah') || settled.includes('correct')) {
      start_navigation(bestMatch); return;
    } else {
      announce("Okay, please say your destination again.", false);
      continue;
    }
  }
  announce("Voice input failed repeatedly. Please type destination instead.", false);
  show_destination_modal();
}

/* ======= Navigation flow ======= */
function start_navigation(destination) {
  if (!currentLocation) { announce("No current location. Scan QR codes first.", false); return; }
  if (!destination) { announce("No destination selected.", false); return; }
  const res = dijkstra(graph, currentLocation, destination);
  if (!res.path.length || res.cost === Infinity) { announce("No path found to that destination.", false); alert("Routing error: no path found."); return; }
  announce(`Navigation started to ${destination}. Total distance ${Math.round(res.cost)} meters.`, true);
  navigationDialog(res.path, res.cost);
}

function navigationDialog(path, total_cost) {
  let idx = 0;
  currentNavigationTarget = path[path.length - 1];
  async function showStep(){
    if (idx >= path.length - 1) {
      const finalText = `Approaching destination ${path[path.length - 1]}. Look for QR code to confirm arrival.`;
      announce(finalText, true);
      overlayText.textContent = `Final: Look for ${path[path.length - 1]} QR`;
      // Restart scanning camera for arrival confirmation if stopped
      setTimeout(()=>{ if (!scannerRunning) startCamera(); }, 1500);
      return;
    }
    const current = path[idx]; const next = path[idx + 1];
    let instruction;
    if (idx === 0) instruction = `${get_initial_direction_simple(node_coords[current], node_coords[next])} towards ${next}.`;
    else instruction = `At ${current}: ${get_turn_direction(node_coords[path[idx-1]], node_coords[current], node_coords[next])} towards ${next}.`;
    const distance = (graph[current] && graph[current][next]) ? graph[current][next] : 0;
    const spoken = `${instruction} Distance ${Math.round(distance)} meters.`;
    announce(spoken, false);
    overlayText.textContent = `Step ${idx+1}: ${instruction}`;
    const ok = confirm(spoken + "\n\nPress OK for next step, Cancel to stop navigation.");
    if (ok) { idx++; setTimeout(showStep, 700); }
    else { announce("Navigation cancelled.", true); currentNavigationTarget = null; overlayText.textContent = "Navigation cancelled"; }
  }
  showStep();
}

/* ======= Arrival handling & QR decoded callback ======= */
function handleDecoded(decoded, color) {
  const decodedClean = decoded.trim();
  if (currentNavigationTarget) {
    const target = (currentNavigationTarget || "").toLowerCase();
    const detected = decodedClean.toLowerCase();
    if (detected === target || detected.includes(target) || target.includes(detected)) {
      log("Arrival confirmed: " + decodedClean);
      announce(`You have arrived at ${decodedClean}.`, true);
      currentLocation = decodedClean; currentNavigationTarget = null;
      stopCamera();
      vibrateArrival();
      setTimeout(()=>{ alert(`Arrival confirmed: ${decodedClean}`); }, 800);
      return;
    } else {
      if (decodedClean !== currentLocation) {
        currentLocation = decodedClean;
        log("Passed checkpoint: " + decodedClean);
        announce(`Passed ${decodedClean}`, false);
      }
      return;
    }
  }
  if (decodedClean !== currentLocation) {
    currentLocation = decodedClean;
    log("Current location updated: " + decodedClean);
    announce(`Current location: ${decodedClean}`, false);
    setTimeout(()=>{ announce("When ready, press Voice Destination and speak your destination.", false); }, 900);
  }
}

/* ======= Map drawing (kept from your previous function) ======= */
function drawMap() {
  const ctx = mapCanvas.getContext('2d');
  ctx.clearRect(0,0,mapCanvas.width,mapCanvas.height);
  const cw = mapCanvas.width, ch = mapCanvas.height, margin = 40;
  const xs = Object.values(node_coords).map(p => p[0]);
  const ys = Object.values(node_coords).map(p => p[1]);
  const minx = Math.min(...xs), maxx = Math.max(...xs);
  const miny = Math.min(...ys), maxy = Math.max(...ys);
  const project = (p) => {
    const sx = (p[0] - minx) / (maxx - minx || 1);
    const sy = (p[1] - miny) / (maxy - miny || 1);
    return [ margin + Math.floor(sx * (cw - margin * 2)), margin + Math.floor(sy * (ch - margin * 2)) ];
  };
  ctx.strokeStyle = "#bbb"; ctx.lineWidth = 1;
  for (const a in graph) {
    for (const b in graph[a]) {
      if (node_coords[a] && node_coords[b]) {
        const pa = project(node_coords[a]); const pb = project(node_coords[b]);
        ctx.beginPath(); ctx.moveTo(pa[0], pa[1]); ctx.lineTo(pb[0], pb[1]); ctx.stroke();
      }
    }
  }
  ctx.font = "14px Arial";
  for (const name in node_coords) {
    const p = project(node_coords[name]);
    if (name === currentLocation) {
      ctx.fillStyle = "#ff4444"; ctx.beginPath(); ctx.arc(p[0], p[1], 8, 0, Math.PI*2); ctx.fill();
    } else {
      ctx.fillStyle = "#333"; ctx.beginPath(); ctx.arc(p[0], p[1], 4, 0, Math.PI*2); ctx.fill();
    }
    ctx.fillStyle = "#000"; ctx.fillText(name, p[0]+10, p[1]+4);
  }
}

/* ======= Event handlers & keyboard shortcuts ======= */
startBtn.onclick = async () => { if (scannerRunning) { announce("Scanner already running.", false); return; } userGesturePerformed = true; await startCamera(); };
stopBtn.onclick = () => { stopCamera(); };
restartBtn.onclick = () => { stopCamera(); foundResults.clear(); actionsTriggered=false; scanStartTime = Date.now(); setTimeout(()=>{ startBtn.click(); },300); };
voiceDestBtn.onclick = () => { userGesturePerformed = true; ask_destination_via_voice(); };
mapBtn.onclick = () => { drawMap(); mapModal.style.display = 'flex'; announce("Map opened. Close when ready.", false); };
closeMap.onclick = () => { mapModal.style.display = 'none'; announce("Map closed.", false); };

window.addEventListener('keydown', (e) => {
  if (e.key === 's' || e.key === 'S') { startBtn.click(); }
  if (e.key === 'v' || e.key === 'V') { voiceDestBtn.click(); }
  if (e.key === 'm' || e.key === 'M') { mapBtn.click(); }
  if (e.key === 'r' || e.key === 'R') { restartBtn.click(); }
  if (e.code === 'Space') { e.preventDefault(); stopBtn.click(); }
});

/* ======= OpenCV initialization ======= */
function onOpenCvReady(){ cvReady = true; log("OpenCV ready"); announce("OpenCV loaded - improved color detection available.", false); }
if (typeof cv !== 'undefined') {
  if (cv && cv.Mat) onOpenCvReady();
  else cv['onRuntimeInitialized'] = onOpenCvReady;
} else {
  setTimeout(()=>{ if (!cvReady) announce("OpenCV not loaded. Falling back to JS color detection.", false); }, 7000);
}

/* ======= Cleanup ======= */
window.addEventListener('beforeunload', ()=>{ if (stream) stream.getTracks().forEach(t=>t.stop()); speechSynthesis.cancel(); });

/* ======= Initialization messages ======= */
announce("Ready. Press Start Scan to begin scanning for three color QR codes.", false);
log("App initialized. Speech recognition available: " + (SR_AVAILABLE ? 'yes' : 'no'));
log("Scan sequence: Red (location) + Green (map) + Blue (accessibility)");

</script>
</body>
</html>
