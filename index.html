<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>VI-Friendly Indoor Navigation (Color QR + Obstacle Alerts)</title>
  <style>
    :root{
      --bg:#000; --card:#0b1220; --accent:#ffd54f; --accent-2:#00e676; --text:#fff;
      --muted:#9aa8b2;
      --btn-h:64px; --btn-font:20px;
    }
    html,body{height:100%; margin:0; background:linear-gradient(180deg,#05070a 0%, #0b0f14 100%); color:var(--text); font-family: system-ui, -apple-system, "Segoe UI", Roboto, Arial; -webkit-font-smoothing:antialiased;}
    .app {
      max-width: 980px;
      margin: 12px auto;
      padding: 18px;
      padding-bottom: 200px;
      background: linear-gradient(180deg, #071018 0, #07121a 100%);
      border-radius: 14px;
      box-shadow: 0 8px 36px rgba(0,0,0,0.6);
      border: 1px solid rgba(255,255,255,0.02);
    }
    header { display:flex; gap:12px; align-items:center; }
    h1 { font-size:24px; margin:0; color:var(--accent); letter-spacing:0.6px; }
    .subtitle { color: var(--muted); font-size:14px; margin-top:4px; }

    .controls { margin:14px 0; display:flex; gap:12px; flex-wrap:wrap; align-items:center; }
    .btn { background:var(--accent); color:#000; border:none; padding:12px 18px; border-radius:12px; font-size:var(--btn-font); height:var(--btn-h); min-width:150px; cursor:pointer; box-shadow:0 8px 18px rgba(0,0,0,0.5); }
    .btn.secondary { background:transparent; color:var(--text); border:2px solid rgba(255,255,255,0.06); }
    .btn.ghost { background:transparent; color:var(--accent); border:2px dashed rgba(255,213,79,0.18); }
    .btn:focus { outline:4px solid rgba(255,213,79,0.25); outline-offset:3px; }
    .select { font-size:18px; padding:12px; border-radius:12px; height:var(--btn-h); background:#07141a; color:var(--text); border:1px solid rgba(255,255,255,0.03); min-width:140px; }
    .btn.green { background:#4caf50; color:#fff; }
    .btn.red { background:#f44336; color:#fff; }
    .btn.yellow { background:#ffeb3b; color:#000; }
    .btn.grey { background:#9e9e9e; color:#fff; }

    .main-controls {
      bottom: 0;
      left: 0;
      right: 0;
      background: #071018;
      padding: 14px;
      display: flex;
      flex-direction: column;
      gap: 12px;
      z-index: 1000;
      box-shadow: 0 -4px 12px rgba(0,0,0,0.6);
    }
    .main-controls .controls-row { display: flex; justify-content: space-between; gap: 12px; }
    .main-controls .controls-row:last-child { justify-content: center; }

    .statusBox { margin-top:12px; padding:14px; background:linear-gradient(180deg,#071018,#06121a); border-radius:12px; border:1px solid rgba(0,255,136,0.03); min-height:100px; display:flex; gap:12px; align-items:flex-start; }
    #leftStatus { flex:1; }
    #overlayText { font-weight:800; font-size:20px; color:var(--text); margin-bottom:6px; }
    #srAnnounce { font-size:17px; color:var(--muted); margin-top:6px; }
    #listeningBox { margin-top:10px; font-size:18px; color:#ffb74d; min-height:22px; }

    .scan-progress { margin-top:10px; display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    .progress-pill { padding:10px 14px; border-radius:999px; background:#071018; color:var(--muted); font-size:18px; border:1px solid rgba(255,255,255,0.02); min-width:200px; text-align:center; }
    .progress-pill.found { background:var(--accent-2); color:#000; font-weight:800; border:2px solid rgba(0,64,0,0.7); }

    #previewWrap { display:flex; gap:12px; margin-top:14px; align-items:flex-start; justify-content:center; }
    #previewCanvas {
      height: auto;
      background: #000;
      border-radius: 10px;
      border: 2px solid #0b1b2a;
      object-fit: cover;
      display:block;
      margin: 0 auto;
    }

    .alerts { padding:12px; border-radius:10px; background:#061217; border:1px solid rgba(255,255,255,0.02); min-height:100px; color:var(--muted); }
    .alerts h4 { margin:0 0 6px 0; color:var(--accent); font-size:16px; }
    .alerts ul { margin:0; padding-left:18px; font-size:16px; color:var(--muted); }
    .alerts li { margin-bottom:6px; }

    #log { margin-top:12px; background:#02060a; color:#b8d3de; padding:12px; border-radius:10px; height:160px; overflow:auto; font-size:14px; border:1px solid rgba(255,255,255,0.02); }

    .map-modal { position:fixed; inset:0; display:none; align-items:center; justify-content:center; background:rgba(0,0,0,0.75); z-index:999; }
    .map-modal .box { background:#071018; padding:14px; max-width:900px; width:95%; max-height:85%; overflow:auto; border-radius:10px; border:2px solid rgba(255,255,255,0.02); color:#fff; }
    #mapCanvas { width:100%; height:auto; border-radius:6px; background:#fff; display:block; }

    footer { margin-top:14px; color:var(--muted); font-size:13px; text-align:center; }

    .visually-hidden { position:absolute !important; height:1px; width:1px; overflow:hidden; clip:rect(1px,1px,1px,1px); white-space:nowrap; }
    @media (max-width:760px){
      #previewCanvas { width:100%; height:260px; }
      .controls { gap:8px; }
      .btn { min-width:120px; font-size:18px; height:56px; }
    }
  </style>

  <!-- External Libraries -->
  <script src="https://cdn.jsdelivr.net/npm/jsqr@1.4.0/dist/jsQR.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <div class="app" role="application" aria-labelledby="appTitle">
    <header>
      <div>
        <h1 id="appTitle">VI Indoor Navigation</h1>
        <div class="subtitle">Color QR navigation • Voice-first • Obstacle alerts</div>
      </div>
    </header>

   <div class="controls" role="region" aria-label="Settings">
    <select id="colorFilter" class="select" aria-label="Filter QR color. Choose Any, Red, Green or Blue">
      <option>Any</option><option>Red</option><option>Green</option><option>Blue</option>
    </select>

    <label style="display:flex; align-items:center; gap:8px; margin-left:6px; color:var(--muted); font-size:16px;">
      <input type="checkbox" id="enableDetect" checked aria-label="Enable object detection"> Enable Object Detection
    </label>
   </div>

   <div class="statusBox" role="status" aria-live="polite">
    <div id="leftStatus">
      <div id="overlayText">Ready — waiting for destination. The app will ask for your final destination first.</div>
      <div id="srAnnounce" aria-live="polite" role="log">Status messages will be read aloud.</div>
      <div id="listeningBox" aria-hidden="true"></div>
      <div class="scan-progress" aria-hidden="false">
        <div id="progressRed" class="progress-pill" role="status">Red QR: Not found</div>
        <div id="progressGreen" class="progress-pill" role="status">Green QR: Not found</div>
        <div id="progressBlue" class="progress-pill" role="status">Blue QR: Not found</div>
      </div>
    </div>

    <div id="alertsPanel">
      <div class="alerts" aria-live="polite">
        <h4>Object Alerts</h4>
        <ul id="alertsList"><li>No recent alerts</li></ul>
      </div>
    </div>
   </div>

   <div id="previewWrap">
     <canvas id="previewCanvas" width="800" height="600" aria-label="Camera preview for sighted helper"></canvas>
   </div>

   <div id="log" aria-live="polite" role="log"></div>

   <div class="map-modal" id="mapModal" role="dialog" aria-modal="true" aria-labelledby="mapTitle">
     <div class="box">
       <h3 id="mapTitle">Map Preview</h3>
       <canvas id="mapCanvas" width="900" height="600"></canvas>
       <div style="text-align:right; margin-top:8px;">
         <button id="closeMap" class="btn secondary" aria-label="Close map">Close</button>
       </div>
     </div>
   </div>

   <div class="controls main-controls" role="region" aria-label="Main controls">
     <div class="controls-row">
       <button id="startBtn" class="btn green" aria-pressed="false" aria-label="Start scanning for QR codes (S)">Start Scan</button>
       <button id="stopBtn" class="btn red" aria-pressed="false" aria-label="Stop scanning (Space)">Stop Scan</button>
       <button id="voiceDestBtn" class="btn yellow" aria-label="Voice destination input (V)">Voice Destination</button>
     </div>

     <div class="controls-row">
       <button id="restartBtn" class="btn grey" aria-label="Restart scanner (R)">Restart</button>
       <button id="mapBtn" class="btn grey" aria-label="Show map (M)">Show Map</button>
     </div>
   </div>

   <footer>Built for visually impaired users — spoken prompts, vibration and object alerts help navigation.</footer>
  </div>

<script>
/* DOM Elements */
const overlayText = document.getElementById('overlayText');
const srAnnounce = document.getElementById('srAnnounce');
const previewCanvas = document.getElementById('previewCanvas');
const previewCtx = previewCanvas.getContext('2d', { willReadFrequently: true });
const canvasDisp = document.createElement('canvas');
const ctxDisp = canvasDisp.getContext('2d', { willReadFrequently: true });
const logEl = document.getElementById('log');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const voiceDestBtn = document.getElementById('voiceDestBtn');
const colorFilterEl = document.getElementById('colorFilter');
const mapBtn = document.getElementById('mapBtn');
const mapModal = document.getElementById('mapModal');
const mapCanvas = document.getElementById('mapCanvas');
const closeMap = document.getElementById('closeMap');
const restartBtn = document.getElementById('restartBtn');
const progressRed = document.getElementById('progressRed');
const progressGreen = document.getElementById('progressGreen');
const progressBlue = document.getElementById('progressBlue');
const enableDetectCheckbox = document.getElementById('enableDetect');
const alertsList = document.getElementById('alertsList');

const log = (m) => { console.log(m); const t = new Date().toLocaleTimeString(); logEl.innerText += `[${t}] ${m}\n`; logEl.scrollTop = logEl.scrollHeight; };
function backendLog(m) { console.log("[BACKEND] " + m); const t = new Date().toLocaleTimeString(); logEl.innerText += `[${t}] [BACKEND] ${m}\n`; logEl.scrollTop = logEl.scrollHeight; }

/* ENHANCED STATE */
const SCAN_SIZE = 360;
let scanBox = { x: 0, y: 0, size: SCAN_SIZE };
let cvReady = false, animationFrameId = null, stream = null, scannerRunning = false;
let foundResults = new Map(), scanStartTime = Date.now(), currentLocation = null;

/* Navigation state */
let finalDestination = null;       // chosen by user at start (persist for session)
let currentNavigationTarget = null;
let navigationActive = false;      // true after finalDestination chosen and before arrival
let navigationStarted = false;     // set when start_navigation run
let isFirstLocationSet = false;    // have we captured the first current location from QR
let actionsTriggered = false;
let latestDetections = [], userGesturePerformed = false;

/* Arrival lock: when true, non-interrupt announcements are suppressed so arrival audio can't be overridden */
let arrivalLocked = false;

/* Object detection model */
let cocoModel = null, cocoReady = false;
const DETECTION_INTERVAL_MS = 900, SCORE_THRESHOLD = 0.45, CENTER_TOLERANCE = 0.25;
const DISTANCE_ESTIMATE_SCALE = 1.6; let lastDetectTime = 0;
const alertCooldown = 3000; const lastAlertAt = {};
const HARMFUL_CLASSES = new Set(['person','chair','couch','bench','dining table','stop sign','tv','suitcase','backpack','bed','toilet']);

/* Simple helpers */
const sleep = ms => new Promise(r=>setTimeout(r,ms));

/* TTS Queue System (supports interrupt) */
const TTS = {
  queue: [], speaking: false,
  speak(text, interrupt=false) {
    if(!text) return;
    if(interrupt){ this.queue=[]; try { speechSynthesis.cancel(); } catch(e){} }
    this.queue.push(text);
    this._maybeSpeak();
  },
  _maybeSpeak() {
    if(this.speaking) return;
    const next = this.queue.shift();
    if(!next) return;
    this.speaking = true;
    const utt = new SpeechSynthesisUtterance(next);
    utt.rate = 1.0;
    utt.text = this._fixPronunciation(next);
    utt.onend = () => {
      this.speaking = false;
      // release arrival lock once utterance ends
      if (arrivalLocked && !speechSynthesis.speaking && !speechSynthesis.pending) {
        arrivalLocked = false;
        log("[ARRIVAL] arrivalLocked cleared after speech end");
      }
      setTimeout(()=>this._maybeSpeak(), 80);
    };
    utt.onerror = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    try { speechSynthesis.speak(utt); } catch(e) { this.speaking = false; }
  },
  _fixPronunciation(text) {
    return text.replace(/\bN(\d+)\b/g, (match, digits) => {
      const spelled = digits.split('').join(' ');
      return `N ${spelled}`;
    });
  }
};

/* announce wrapper: suppresses non-interrupt announcements while arrivalLocked */
function announce(text, interrupt=false) {
  if (arrivalLocked && !interrupt) {
    log(`[ANNOUNCE suppressed because arrivalLocked] ${text}`);
    return;
  }
  overlayText.textContent = text;
  srAnnounce.textContent = text;
  TTS.speak(text, interrupt);
  log(`[ANNOUNCE] ${text}`);
}

/* Speech recognition availability */
let SR_AVAILABLE = false;
try { const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition; if (SpeechRecognition) SR_AVAILABLE = true; } catch(e){ SR_AVAILABLE=false; }

/* Color processing & QR detection helpers (unchanged) */
function createColorMask(imageData, color) {
  const data = imageData.data; const w = imageData.width, h = imageData.height;
  const out = new Uint8ClampedArray(data.length);
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i], g = data[i+1], b = data[i+2];
    let hit = false;
    if (color === 'red') hit = (r > g + 25 && r > b + 25 && r > 90) || (r > 140 && r > g * 1.3 && r > b * 1.3);
    else if (color === 'green') hit = (g > r + 25 && g > b + 25 && g > 90) || (g > 140 && g > r * 1.2 && g > b * 1.2);
    else hit = (b > r + 20 && b > g + 20 && b > 70) || (b > 110 && b > r * 1.05 && b > g * 1.05);
    if (hit) { out[i]=out[i+1]=out[i+2]=255; out[i+3]=255; } else { out[i]=out[i+1]=out[i+2]=0; out[i+3]=255; }
  }
  return new ImageData(out,w,h);
}

function extractColorChannel(imageData, channel) {
  const data = imageData.data; const out = new Uint8ClampedArray(data.length);
  for (let i=0;i<data.length;i+=4){
    const r = data[i], g = data[i+1], b = data[i+2];
    let intensity = 0;
    if (channel === 'red') intensity = r;
    else if (channel === 'green') intensity = g;
    else intensity = Math.max(b, Math.floor((b*1.6 + Math.max(r,g)*0.2)));
    intensity = Math.min(255, Math.max(0, intensity));
    out[i]=out[i+1]=out[i+2]=intensity; out[i+3]=255;
  }
  return new ImageData(out, imageData.width, imageData.height);
}

function enhanceBlueContrast(imageData) {
  const data = imageData.data; const out = new Uint8ClampedArray(data.length);
  for (let i=0;i<data.length;i+=4){
    const r = data[i], g = data[i+1], b = data[i+2];
    let intensity = b;
    if (b > r && b > g) intensity = Math.min(255, Math.round(b * 1.8));
    else if (b > 70) intensity = Math.min(255, Math.round(b * 1.3));
    else intensity = Math.round((r+g+b)/3 * 0.55);
    out[i]=out[i+1]=out[i+2]=intensity; out[i+3]=255;
  }
  return new ImageData(out, imageData.width, imageData.height);
}

function detectWithOpenCV(imageData, color) {
  if (!cvReady) return null;
  try {
    const src = cv.matFromImageData(imageData);
    const rgb = new cv.Mat(); cv.cvtColor(src, rgb, cv.COLOR_RGBA2RGB);
    const hsv = new cv.Mat(); cv.cvtColor(rgb, hsv, cv.COLOR_RGB2HSV);
    const mask = new cv.Mat();
    if (color === 'red') {
      const lower1 = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [0, 80, 40, 0]);
      const upper1 = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [10, 255, 255, 255]);
      const lower2 = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [170, 80, 40, 0]);
      const upper2 = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [180, 255, 255, 255]);
      const m1 = new cv.Mat(), m2 = new cv.Mat();
      cv.inRange(hsv, lower1, upper1, m1);
      cv.inRange(hsv, lower2, upper2, m2);
      cv.add(m1, m2, mask);
      m1.delete(); m2.delete(); lower1.delete(); upper1.delete(); lower2.delete(); upper2.delete();
    } else if (color === 'green') {
      const low = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [35, 60, 40, 0]);
      const high = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [85, 255, 255, 255]);
      cv.inRange(hsv, low, high, mask); low.delete(); high.delete();
    } else {
      const low = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [90, 40, 30, 0]);
      const high = new cv.Mat(hsv.rows, hsv.cols, hsv.type(), [140, 255, 255, 255]);
      cv.inRange(hsv, low, high, mask); low.delete(); high.delete();
    }
    const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3,3));
    cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel);
    cv.morphologyEx(mask, mask, cv.MORPH_CLOSE, kernel);
    const rgba = new cv.Mat(); cv.cvtColor(mask, rgba, cv.COLOR_GRAY2RGBA);
    const out = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
    src.delete(); rgb.delete(); hsv.delete(); mask.delete(); kernel.delete(); rgba.delete();
    return out;
  } catch (e) { console.warn("OpenCV detect failed:", e); return null; }
}

function detect_colored_qr_in_frame_js(imageData, targetColor=null) {
  const COLORS = ['red','green','blue'];
  for (const color of COLORS) {
    if (targetColor && color !== targetColor) continue;
    try {
      const chImg = extractColorChannel(imageData, color);
      const code = jsQR(chImg.data, chImg.width, chImg.height, { inversionAttempts: 'attemptBoth' });
      if (code && code.data) {
        let boxArea = null;
        if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
          const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
          const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
          boxArea = Math.abs(w*h);
        }
        return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Enhanced-Channel', location: code.location || null, boxArea };
      }
    } catch(e){ console.warn('Enhanced channel decode error', color, e); }

    if (color === 'blue') {
      try {
        const maskImg = createColorMask(imageData, color);
        const code = jsQR(maskImg.data, maskImg.width, maskImg.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          let boxArea = null;
          if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
            const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
            const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
            boxArea = Math.abs(w*h);
          }
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Color-Mask', location: code.location || null, boxArea };
        }
      } catch(e){ console.warn('Color mask decode error', color, e); }
    }

    if (cvReady) {
      try {
        const cvProcessed = detectWithOpenCV(imageData, color);
        if (cvProcessed) {
          const code = jsQR(cvProcessed.data, cvProcessed.width, cvProcessed.height, { inversionAttempts: 'attemptBoth' });
          if (code && code.data) {
            let boxArea = null;
            if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
              const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
              const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
              boxArea = Math.abs(w*h);
            }
            return { found: true, decoded: code.data.trim(), colorFound: color, method: 'OpenCV-HSV', location: code.location || null, boxArea };
          }
        }
      } catch(e){ console.warn('OpenCV approach failed for', color, e); }
    }

    if (color === 'blue') {
      try {
        const enhanced = enhanceBlueContrast(imageData);
        const code = jsQR(enhanced.data, enhanced.width, enhanced.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          let boxArea = null;
          if (code.location && code.location.topLeftCorner && code.location.bottomRightCorner) {
            const w = Math.hypot(code.location.topRightCorner.x - code.location.topLeftCorner.x, code.location.topRightCorner.y - code.location.topLeftCorner.y);
            const h = Math.hypot(code.location.bottomLeftCorner.x - code.location.topLeftCorner.x, code.location.bottomLeftCorner.y - code.location.topLeftCorner.y);
            boxArea = Math.abs(w*h);
          }
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Blue-Enhanced', location: code.location || null, boxArea };
        }
      } catch(e){ console.warn('Blue enhancement failed', e); }
    }
  }
  return { found: false };
}

/* Progress display */
function updateProgressDisplay() {
  const colors = ['red','green','blue'];
  let foundCount = 0;
  colors.forEach(color => {
    const el = color === 'red' ? progressRed : color === 'green' ? progressGreen : progressBlue;
    if (foundResults.has(color)) {
      foundCount++; el.classList.add('found'); el.textContent = `${color.toUpperCase()} QR: ${foundResults.get(color).decoded}`;
    } else { el.classList.remove('found'); el.textContent = `${color.charAt(0).toUpperCase() + color.slice(1)} QR: Scanning...`; }
  });
  if (foundCount > 0) announce(`${foundCount} of 3 QR codes found.`, false);
}

/* Vibration helpers */
let lastVibrateAt = 0;
function vibrateProximityFromRatio(ratio) {
  if (!('vibrate' in navigator)) return;
  const now = Date.now();
  if (now - lastVibrateAt < 160) return;
  lastVibrateAt = now;
  const intensity = Math.min(1, Math.max(0, (ratio - 0.02) / 0.6));
  const dur = Math.round(40 + intensity * 280);
  const pattern = [dur, 40];
  try { navigator.vibrate(pattern); } catch(e){}
}
function vibrateApproachPattern(ratio) {
  if (!('vibrate' in navigator)) return;
  if (ratio < 0.12) return;
  const norm = Math.min(1, Math.max(0, (ratio - 0.12) / 0.68));
  const pulses = 2 + Math.round(norm * 6);
  const strongMs = 60 + Math.round(norm * 220);
  const gapMs = 40;
  const pattern = [];
  for (let i=0;i<pulses;i++){ pattern.push(strongMs); if(i < pulses-1) pattern.push(gapMs); }
  try { navigator.vibrate(pattern); } catch(e){}
}
function vibrateArrival() {
  if (!('vibrate' in navigator)) return;
  try { navigator.vibrate([80,40,80,40,120]); } catch(e){}
}

/* Camera start/stop & processing loop - when finalDestination chosen we will auto-start camera */
let videoElementRef = null;
async function startCamera() {
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } }, audio: false
    });
    const video = document.createElement('video');
    video.autoplay = true; video.playsInline = true; video.muted = true;
    video.srcObject = stream;
    await video.play();
    videoElementRef = video;

    canvasDisp.width = video.videoWidth || 1280;
    canvasDisp.height = video.videoHeight || 720;
    previewCanvas.width = Math.min(1280, canvasDisp.width);
    previewCanvas.height = Math.min(720, canvasDisp.height);

    scanBox.size = Math.min(SCAN_SIZE, Math.floor(Math.min(canvasDisp.width, canvasDisp.height) * 0.5));
    scanBox.x = Math.floor((canvasDisp.width - scanBox.size)/2);
    scanBox.y = Math.floor((canvasDisp.height - scanBox.size)/2);

    scanStartTime = Date.now();
    // Do not clear finalDestination — we want it preserved
    // but reset foundResults so fresh scanning occurs
    foundResults.clear();
    actionsTriggered = false;
    scannerRunning = true;

    // announce context-aware message
    if (navigationActive && finalDestination) {
      announce(`Camera started. Scanning for current location to guide you to ${finalDestination}.`, true);
    } else {
      announce("Camera started. Scanning for QR codes. Point the phone at the QR.", true);
    }

    updateProgressDisplay();
    processFrame(video);
    startBtn.setAttribute('aria-pressed','true');
    userGesturePerformed = true;
    return true;
  } catch(e) {
    announce("Camera access denied or unavailable. Check permissions and try again.", true);
    log("Camera error: " + e);
    return false;
  }
}
function stopCamera() {
  if (stream) stream.getTracks().forEach(t => t.stop());
  if (animationFrameId) { cancelAnimationFrame(animationFrameId); animationFrameId = null; }
  scannerRunning = false;
  startBtn.setAttribute('aria-pressed','false');
  log("Camera stopped.");
  // DO NOT auto-announce "Scanner stopped" during arrival lock because it would override arrival voice
  if (!arrivalLocked) announce("Scanner stopped.", true);
}

/* Load coco model */
async function loadCocoModel() {
  try {
    backendLog("Loading coco-ssd...");
    cocoModel = await cocoSsd.load();
    cocoReady = true;
    backendLog("coco-ssd loaded");
  } catch(e) {
    cocoReady = false;
    backendLog("coco load failed: " + e);
  }
}
loadCocoModel();

/* Draw preview */
function drawPreviewFrame(tmpCanvas) {
  try {
    previewCtx.clearRect(0,0,previewCanvas.width, previewCanvas.height);
    previewCtx.drawImage(tmpCanvas, 0, 0, previewCanvas.width, previewCanvas.height);

    const sx = previewCanvas.width / tmpCanvas.width;
    const sy = previewCanvas.height / tmpCanvas.height;
    previewCtx.strokeStyle = 'rgba(0,255,128,0.9)';
    previewCtx.lineWidth = Math.max(2, Math.round(previewCanvas.width * 0.004));
    previewCtx.strokeRect(Math.round(scanBox.x*sx), Math.round(scanBox.y*sy), Math.round(scanBox.size*sx), Math.round(scanBox.size*sy));

    if (latestDetections && latestDetections.length && enableDetectCheckbox.checked) {
      previewCtx.save();
      previewCtx.lineWidth = Math.max(2, Math.round(previewCanvas.width * 0.004));
      for (const d of latestDetections) {
        const [x,y,w,h] = d.bbox;
        const rx = Math.round(x * sx), ry = Math.round(y * sy), rw = Math.round(w * sx), rh = Math.round(h * sy);
        previewCtx.strokeStyle = 'rgba(255,80,80,0.95)';
        previewCtx.fillStyle = 'rgba(255,80,80,0.85)';
        previewCtx.beginPath();
        previewCtx.strokeRect(rx, ry, rw, rh);
        const label = `${d.class} ${(d.score*100).toFixed(0)}%`;
        previewCtx.font = `${14}px Arial`;
        const tw = previewCtx.measureText(label).width + 10;
        previewCtx.fillRect(rx, Math.max(ry-22, 0), tw, 20);
        previewCtx.fillStyle = '#fff';
        previewCtx.fillText(label, rx+5, Math.max(ry-8, 12));
        previewCtx.fillStyle = 'rgba(255,80,80,0.85)';
      }
      previewCtx.restore();
    }
  } catch(e) { console.warn("drawPreviewFrame error", e); }
}

/* Frame processing */
let qrDecoderBusy = false, frameSkipCounter = 0;
async function processFrame(video) {
  if (!scannerRunning) return;
  animationFrameId = requestAnimationFrame(() => processFrame(video));
  if (!video || video.readyState < 2) return;

  frameSkipCounter++;
  if (frameSkipCounter % 2 !== 0 && foundResults.size < 3) return;

  canvasDisp.width = video.videoWidth || canvasDisp.width;
  canvasDisp.height = video.videoHeight || canvasDisp.height;

  ctxDisp.drawImage(video, 0, 0, canvasDisp.width, canvasDisp.height);

  const tmp = document.createElement('canvas');
  tmp.width = canvasDisp.width; tmp.height = canvasDisp.height;
  const tmpCtx = tmp.getContext('2d');
  tmpCtx.drawImage(canvasDisp, 0, 0);

  tmpCtx.strokeStyle = '#00ff88'; tmpCtx.lineWidth = Math.max(2, Math.round(canvasDisp.width * 0.004));
  tmpCtx.strokeRect(scanBox.x, scanBox.y, scanBox.size, scanBox.size);

  if (latestDetections && latestDetections.length > 0 && enableDetectCheckbox.checked) {
    tmpCtx.lineWidth = Math.max(2, Math.round(canvasDisp.width * 0.004));
    for (const d of latestDetections) {
      tmpCtx.strokeStyle = 'rgba(255,80,80,0.9)'; tmpCtx.fillStyle = 'rgba(255,80,80,0.8)';
      const [x,y,w,h] = d.bbox;
      tmpCtx.strokeRect(x, y, w, h);
      const label = `${d.class} ${(d.score*100).toFixed(0)}%`;
      const labelW = tmpCtx.measureText(label).width + 10;
      tmpCtx.fillRect(x, Math.max(y-22,0), labelW, 20);
      tmpCtx.fillStyle = '#fff'; tmpCtx.fillText(label, x+5, Math.max(y-8, 12));
      tmpCtx.fillStyle = 'rgba(255,80,80,0.8)';
    }
  }

  drawPreviewFrame(tmp);

  if (qrDecoderBusy) return;
  qrDecoderBusy = true;

  setTimeout(async () => {
    try {
      const imageData = ctxDisp.getImageData(scanBox.x, scanBox.y, scanBox.size, scanBox.size);
      const targetFilter = (colorFilterEl.value === "Any") ? null : colorFilterEl.value.toLowerCase();
      const colorOrder = targetFilter ? [targetFilter] : ['blue','red','green'];
      for (const color of colorOrder) {
        if (foundResults.has(color)) continue;
        const detection = detect_colored_qr_in_frame_js(imageData, color);
        if (detection.found && detection.decoded) {
          const decodedClean = detection.decoded.trim();
          foundResults.set(color, { decoded: decodedClean, method: detection.method || 'unknown', boxArea: detection.boxArea || null });
          announce(`${color} QR found: ${decodedClean}`, true);
          updateProgressDisplay();
          if (detection.boxArea) {
            const scanArea = scanBox.size * scanBox.size;
            const ratio = detection.boxArea / scanArea;
            vibrateProximityFromRatio(ratio);
            if (ratio >= 0.15) vibrateApproachPattern(ratio);
          }
          handleDecoded(decodedClean, color);
          break;
        }
      }

      // If all three found and not yet triggered, trigger summary (keeps backward compatibility)
      const requiredColors = ['red', 'green', 'blue'];
      const foundColors = Array.from(foundResults.keys());
      const allColorsFound = requiredColors.every(color => foundColors.includes(color));
      if (!actionsTriggered && allColorsFound) {
        actionsTriggered = true;
        triggerAllActionsOnce();
      }

      /* Object detection (same as before) */
      const now = performance.now();
      if (enableDetectCheckbox.checked && cocoReady && (now - lastDetectTime > DETECTION_INTERVAL_MS)) {
        lastDetectTime = now;
        try {
          const off = document.createElement('canvas');
          const D_W = 480;
          const scale = D_W / canvasDisp.width;
          off.width = D_W;
          off.height = Math.floor(canvasDisp.height * scale);
          const offCtx = off.getContext('2d');
          offCtx.drawImage(canvasDisp, 0, 0, off.width, off.height);
          const predictions = await cocoModel.detect(off);
          const preds = predictions.filter(p => p.score >= SCORE_THRESHOLD);
          const scaleBack = canvasDisp.width / off.width;
          latestDetections = preds.map(p => {
            const [x,y,w,h] = p.bbox;
            return { class: p.class, score: p.score, bbox: [x*scaleBack, y*scaleBack, w*scaleBack, h*scaleBack] };
          });

          if (latestDetections.length) updateAlertsList(latestDetections.slice(0,4)); else updateAlertsList([]);

          // obstacle logic unchanged
          let candidate = null; const fh = canvasDisp.height; const fw = canvasDisp.width;
          for (const det of latestDetections) {
            if (!HARMFUL_CLASSES.has(det.class)) continue;
            const [x,y,w,h] = det.bbox; const cx = x + w/2; const centerDelta = Math.abs(cx - fw/2) / fw;
            const score = (h / fh) * (1.0 - Math.min(centerDelta / 0.5, 1.0));
            if (!candidate || score > candidate.score) candidate = {det, score};
          }
          if (candidate) {
            const det = candidate.det; const [x,y,w,h] = det.bbox; const cx = x + w/2; const centerDelta = Math.abs(cx - fw/2) / fw;
            const isAhead = (centerDelta <= CENTER_TOLERANCE) && (h / fh >= 0.06);
            if (isAhead) {
              const cls = det.class;
              const nowTs = Date.now();
              if (!lastAlertAt[cls] || (nowTs - lastAlertAt[cls] > alertCooldown)) {
                const ratio = (h / fh);
                let distMeters = (DISTANCE_ESTIMATE_SCALE / Math.max(ratio, 0.02));
                distMeters = Math.min(Math.max(distMeters, 0.2), 50.0);
                if (distMeters <= 5.0) {
                  announce(`Obstacle ahead: ${cls}, approximately ${distMeters.toFixed(1)} meters.`, false);
                  lastAlertAt[cls] = nowTs;
                  log(`[OBSTACLE] ${cls} @ ${distMeters.toFixed(1)}m`);
                }
              }
            }
          }
        } catch(e) { console.warn("Object detection error", e); }
      }

    } catch(e) {
      console.error("Frame processing error:", e);
    } finally {
      qrDecoderBusy = false;
    }
  }, 36);
}

/* Alerts list UI */
function updateAlertsList(dets) {
  alertsList.innerHTML = '';
  for (const d of dets) {
    const li = document.createElement('li');
    li.textContent = `${d.class} ${(d.score*100).toFixed(0)}%`;
    alertsList.appendChild(li);
  }
  if (dets.length === 0) {
    const li = document.createElement('li'); li.textContent = 'No recent alerts'; alertsList.appendChild(li);
  }
}

/* --- CRITICAL: Navigation & QR handling modifications to meet requested flow --- */

/*
 handleDecoded:
 - When finalDestination is set and navigationActive true:
    - if decoded == finalDestination -> arrival: stop camera, lock arrival audio, vibrate, speak arrival (interrupting other TTS)
    - else if decoded is a checkpoint -> announce and continue
 - When finalDestination not set: first QR scanned sets currentLocation (first location detected)
 - When currentLocation set for first time and finalDestination already exists: start navigation
*/
function handleDecoded(decoded, color) {
  const decodedClean = decoded.trim();
  // If we already are in navigation mode (user picked final destination earlier)
  if (navigationActive && finalDestination) {
    const target = (finalDestination || "").toLowerCase();
    const detected = decodedClean.toLowerCase();
    if (detected === target || detected.includes(target) || target.includes(detected)) {
      log("Arrival confirmed for final destination: " + decodedClean);
      // stop camera immediately and lock arrival audio so nothing overrides it
      try { speechSynthesis.cancel(); } catch(e) {}
      arrivalLocked = true;
      stopCamera(); // stops camera & scanning
      vibrateArrival();
      // Speak arrival with interrupt -> clears any queued TTS and starts arrival message
      TTS.speak(`You have arrived at ${decodedClean}.`, true);
      // ensure arrivalLocked stays until speech ends (TTS._maybeSpeak clears it when utterance ends)
      currentLocation = decodedClean;
      navigationActive = false;
      navigationStarted = false;
      currentNavigationTarget = null;
      finalDestination = null; // optional: clear destination after arrival to require new flow next time
      return;
    } else {
      // checkpoint (non-final)
      if (decodedClean !== currentLocation) {
        currentLocation = decodedClean;
        log("Navigation checkpoint update: " + decodedClean);
        announce(`Passed ${decodedClean}. Continuing to ${finalDestination}.`, false);
      }
      return;
    }
  }

  // If finalDestination not set yet, treat first QR scanned as initial location
  if (!isFirstLocationSet) {
    if (decodedClean !== currentLocation) {
      currentLocation = decodedClean;
      isFirstLocationSet = true;
      log("Initial location captured: " + decodedClean);
      announce(`Current location detected ${decodedClean}.`, false);
      // If user already chose finalDestination earlier (rare), automatically start navigation
      if (finalDestination && !navigationStarted) {
        // small delay to allow TTS to finish announcing current location before navigation begins
        setTimeout(() => {
          if (!navigationStarted) {
            start_navigation(finalDestination);
          }
        }, 900);
      }
    }
    return;
  }

  // Otherwise just update location normally
  if (decodedClean !== currentLocation) {
    currentLocation = decodedClean;
    log("Location updated: " + decodedClean);
    announce(`Location updated: ${decodedClean}`, false);
  }
}

/* triggerAllActionsOnce kept for backwards compatibility; does not change flow for initial prompt */
function triggerAllActionsOnce() {
  if (actionsTriggered) return;
  const requiredColors = ['red', 'green', 'blue'];
  const foundColors = Array.from(foundResults.keys());
  const allColorsFound = requiredColors.every(color => foundColors.includes(color));
  if (!allColorsFound) return;
  actionsTriggered = true;
  log("ALL THREE COLOR QR CODES DETECTED - TRIGGERING ACTIONS");
  announce("All three QR codes detected. Processing information now.", true);
  const greenQR = foundResults.get('green')?.decoded || '';
  const blueQR = foundResults.get('blue')?.decoded || '';
  const redQR = foundResults.get('red')?.decoded || '';
  currentLocation = redQR; isFirstLocationSet = true;
  stopCamera();
  setTimeout(() => { announce("Map information available.", false); drawMap(); mapModal.style.display = 'flex'; }, 700);
  setTimeout(() => { announce("Accessibility information: " + blueQR, false); }, 1500);
  setTimeout(() => { announce("Your current location is " + redQR, false); }, 2500);
}

/* Map & routing (unchanged except start_navigation will not be called until currentLocation exists) */
const node_coords = {
  "Female Toilet (NGT1)": [2009, 1357],"Male Toilet (NGT2)": [1955, 1357],"N001 (backdoor)": [2100, 1135],
  "N001": [1907, 1121],"N002": [1651, 1097],"N003": [1387, 1074],"N004": [892, 1097],
  "N005": [638, 1115],"N006": [383, 1139],"N007": [127, 1158],"N008": [4, 1330],
  "Female Toilet (NGT5)": [357, 1350],"Male Toilet (NGT4)": [403, 1351],"N009": [492, 1330],
  "N010": [822, 1335],"N011": [1251, 1340],"N012": [1597, 1340],
};
const graph_raw = {
  "Female Toilet (NGT1)": {"Male Toilet (NGT2)": 1.89},"N001": {"Female Toilet (NGT1)": 9.00, "N001 (backdoor)": 6.77, "N002": 9.00},
  "N002": {"N003": 9.28},"N003": {"N004": 17.35},"N004": {"N005": 8.91},"N005": {"N006": 8.97},
  "N006": {"Male Toilet (NGT4)": 7.45, "Female Toilet (NGT5)": 7.44, "N007": 8.99},"N007": {"N008": 7.40},
  "N008": {"Female Toilet (NGT5)": 12.38},"Female Toilet (NGT5)": {"Male Toilet (NGT4)": 1.61},
  "Male Toilet (NGT4)": {"N009": 3.20},"N009": {"N010": 11.55},"N010": {"N011": 15.02},
  "N011": {"N012": 12.11},"N012": {"Male Toilet (NGT2)": 12.55}
};
function add_bidirectional_edges(graph_in) {
  const new_graph = {};
  for (const k in graph_in) new_graph[k] = {};
  for (const from in graph_in) {
    for (const to in graph_in[from]) {
      const w = graph_in[from][to];
      new_graph[from][to] = w;
      if (!new_graph[to]) new_graph[to] = {};
      new_graph[to][from] = w;
    }
  }
  return new_graph;
}
const graph = add_bidirectional_edges(graph_raw);

function drawMap() {
  const ctx = mapCanvas.getContext('2d'); ctx.clearRect(0,0,mapCanvas.width,mapCanvas.height);
  const cw = mapCanvas.width, ch = mapCanvas.height, margin = 40;
  const xs = Object.values(node_coords).map(p => p[0]); const ys = Object.values(node_coords).map(p => p[1]);
  const minx = Math.min(...xs), maxx = Math.max(...xs), miny = Math.min(...ys), maxy = Math.max(...ys);
  const project = (p) => {
    const sx = (p[0] - minx) / (maxx - minx || 1);
    const sy = (p[1] - miny) / (maxy - miny || 1);
    return [ margin + Math.floor(sx * (cw - margin * 2)), margin + Math.floor(sy * (ch - margin * 2)) ];
  };
  ctx.strokeStyle = "#bbb"; ctx.lineWidth = 1;
  for (const a in graph) { for (const b in graph[a]) {
    if (node_coords[a] && node_coords[b]) { const pa = project(node_coords[a]), pb = project(node_coords[b]);
      ctx.beginPath(); ctx.moveTo(pa[0], pa[1]); ctx.lineTo(pb[0], pb[1]); ctx.stroke();
    }
  } }
  const labels = []; ctx.font = "12px Arial";
  for (const name in node_coords) {
    const p = project(node_coords[name]); const text = name; const padding = 6; const textW = Math.min(300, ctx.measureText(text).width);
    let lx = p[0] + 8; let ly = p[1] - 6; const labelH = 18;
    if (lx + textW + padding * 2 > cw - margin) lx = p[0] - textW - padding * 2 - 8;
    if (lx < margin) lx = margin; if (ly < margin) ly = margin;
    labels.push({ name, p, lx, ly, textW, labelH, padding });
  }
  for (let i = 0; i < labels.length; i++) {
    const a = labels[i];
    for (let j = 0; j < i; j++) {
      const b = labels[j];
      const aLeft = a.lx, aRight = a.lx + a.textW + a.padding*2;
      const aTop = a.ly, aBottom = a.ly + a.labelH + a.padding;
      const bLeft = b.lx, bRight = b.lx + b.textW + b.padding*2;
      const bTop = b.ly, bBottom = b.ly + b.labelH + b.padding;
      const overlapX = !(aRight < bLeft || aLeft > bRight);
      const overlapY = !(aBottom < bTop || aTop > bBottom);
      if (overlapX && overlapY) a.ly = bBottom + 4;
    }
  }
  for (const lbl of labels) {
    const p = lbl.p;
    if (currentLocation && lbl.name === currentLocation) { ctx.fillStyle = "#ff4444"; ctx.beginPath(); ctx.arc(p[0], p[1], 10, 0, Math.PI*2); ctx.fill(); }
    else if (typeof destinationNode !== "undefined" && lbl.name === destinationNode) { ctx.fillStyle = "#22bb33"; ctx.beginPath(); ctx.arc(p[0], p[1], 9, 0, Math.PI*2); ctx.fill(); }
    else { ctx.fillStyle = "#333"; ctx.beginPath(); ctx.arc(p[0], p[1], 5, 0, Math.PI*2); ctx.fill(); }
    const bx = lbl.lx, by = lbl.ly - 4, bw = lbl.textW + lbl.padding * 2, bh = lbl.labelH + lbl.padding / 1.5;
    ctx.fillStyle = 'rgba(255,255,255,0.9)'; roundRect(ctx, bx, by, bw, bh, 6, true, false); ctx.fillStyle = '#000';
    ctx.fillText(lbl.name, bx + lbl.padding, by + bh / 1.35);
    ctx.strokeStyle = 'rgba(0,0,0,0.15)'; ctx.lineWidth = 1; ctx.beginPath(); ctx.moveTo(p[0], p[1]); ctx.lineTo(bx + 4, by + bh / 2); ctx.stroke();
  }
}
function roundRect(ctx, x, y, w, h, r, fill, stroke) {
  if (typeof r === 'undefined') r = 5; ctx.beginPath(); ctx.moveTo(x+r, y);
  ctx.arcTo(x+w, y, x+w, y+h, r); ctx.arcTo(x+w, y+h, x, y+h, r); ctx.arcTo(x, y+h, x, y, r);
  ctx.arcTo(x, y, x+w, y, r); ctx.closePath(); if (fill) ctx.fill(); if (stroke) ctx.stroke();
}

/* Destination selection modal updated to allow selecting destination BEFORE scanning */
function show_destination_modal() {
  const candidates = Object.keys(node_coords);
  const candidateList = candidates.map((p,i)=>`${i+1}. ${p}`).join('\n');
  announce("Opening text selection. Check the screen for options.", false);
  const dest = prompt(`Available destinations:\n${candidateList}\n\nType name or number:`);
  if (!dest) { announce("No destination selected.", false); return; }
  let destination = dest.trim();
  const destNumber = parseInt(destination);
  if (!isNaN(destNumber) && destNumber >=1 && destNumber <= candidates.length) {
    destination = candidates[destNumber-1];
  } else {
    const best = findBestLocationMatch(destination, candidates);
    if (best) destination = best;
    else { announce("Destination not found. Please try voice input.", false); setTimeout(()=>ask_destination_via_voice(), 600); return; }
  }
  announce(`You selected ${destination}. Confirming.`, false);
  if (confirm(`Navigate to: ${destination}?`)) {
    finalDestination = destination;
    navigationActive = true;
    announce(`Final destination set to ${finalDestination}. Now starting camera to detect your current location.`, true);
    // Start camera so we can scan red QR for current location
    startCamera();
  } else { announce("Selection cancelled. Try again.", false); setTimeout(()=>show_destination_modal(), 500); }
}

/* Fuzzy matching function (unchanged) */
function findBestLocationMatch(input, candidates) {
  if (!input || !candidates || candidates.length === 0) return null;
  const normalize = s => (s || '').toLowerCase().replace(/[^a-z0-9\s()]/g,' ').replace(/\s+/g,' ').trim();
  const q = normalize(input); if (!q) return null;
  for (const c of candidates) if (normalize(c) === q) return c;
  const nodePattern = /^n\s*(\d+)$/; const qMatch = q.match(nodePattern);
  if (qMatch) {
    const digits = qMatch[1];
    for (const c of candidates) {
      const cNorm = normalize(c);
      if (cNorm.includes(`n ${digits.padStart(3, '0')}`)) return c;
      if (cNorm.includes(`n${digits.padStart(3, '0')}`)) return c;
      if (cNorm.includes(`n ${digits}`)) return c;
    }
  }
  const qTokens = q.split(/\s+/).filter(Boolean);
  let best=null, bestScore=0;
  for (const cand of candidates) {
    const cNorm = normalize(cand); const cTokens = cNorm.split(/\s+/).filter(Boolean);
    let matched = 0;
    for (const qt of qTokens) {
      if (cTokens.includes(qt)) { matched++; continue; }
      if (/^\d+$/.test(qt)) {
        const foundDigitMatch = cTokens.some(ct => { const paddedQt = qt.padStart(3,'0'); return ct.includes(paddedQt) || ct === qt; });
        if (foundDigitMatch) { matched++; continue; }
      }
      const prefixHit = cTokens.some(ct => ct.startsWith(qt) && ct.length - qt.length <= 3);
      if (prefixHit) { matched++; continue; }
    }
    const score = matched / qTokens.length;
    if (score > bestScore || (score === bestScore && best && cNorm.length < normalize(best).length)) { best = cand; bestScore = score; }
  }
  if (bestScore > 0) return best;
  for (const cand of candidates) { const cNorm = normalize(cand); if (cNorm.includes(q)) return cand; }
  return null;
}

/* Speech recognition helper */
function startSpeechRecognition({lang='en-US', interim=true, timeout=9000, onInterim=null} = {}) {
  return new Promise((resolve) => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) { resolve(null); return; }
    let recognition;
    try { recognition = new SR(); } catch(e) { resolve(null); return; }
    recognition.lang = lang; recognition.interimResults = interim; recognition.maxAlternatives = 3;
    let finalTranscript = ''; let resolved = false;
    const timer = setTimeout(() => { if (!resolved) { resolved = true; try { recognition.stop(); } catch(e){}; resolve(null); } }, timeout);
    recognition.onresult = (evt) => {
      const results = Array.from(evt.results);
      const interimText = results.map(r => r[0].transcript).join(' ');
      if (onInterim) onInterim(interimText);
      for (const r of results) if (r.isFinal) finalTranscript = r[0].transcript;
      if (finalTranscript && !resolved) { resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(e){}; resolve(finalTranscript.trim()); }
    };
    recognition.onend = () => { if (resolved) return; resolved = true; clearTimeout(timer); resolve(finalTranscript ? finalTranscript.trim() : null); };
    recognition.onerror = (e) => { if (resolved) return; resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(err){}; resolve(null); };
    try { recognition.start(); } catch(e) { clearTimeout(timer); resolve(null); }
  });
}

/* Interpret yes/no answers robustly */
function interpretConfirmation(text) {
  if (!text) return 'unknown';
  const s = text.toLowerCase().trim();
  const strongYes = /^(yes|yeah|yep|yup|correct|right|affirmative|confirm|ok|okay)$/;
  if (strongYes.test(s)) return 'yes';
  const strongNo = /^(no|nope|nah|wrong|incorrect|cancel|stop)$/;
  if (strongNo.test(s)) return 'no';
  const hasYes = /\b(yes|yeah|yep|yup|correct|right|affirmative|confirm|ok|okay)\b/.test(s);
  const hasNo = /\b(no|nope|nah|not|wrong|incorrect|cancel|stop)\b/.test(s);
  if (hasYes && !hasNo) return 'yes';
  if (hasNo && !hasYes) return 'no';
  if (hasYes && hasNo) return 'ambiguous';
  return 'unknown';
}

/* --- Modified: ask_destination_via_voice now works even if currentLocation is not set yet.
   When user confirms destination, we set finalDestination and start camera to detect current location.
*/
async function ask_destination_via_voice(){
  // Allow destination even without currentLocation (user requested)
  if (!SR_AVAILABLE) { announce("Speech recognition not available. Please use text input.", false); show_destination_modal(); return; }

  let tries = 0;
  const maxTries = 4;
  while (tries < maxTries) {
    tries++;
    announce("Please say your final destination after the beep.", true);
    await sleep(700);

    const interimBox = document.getElementById('listeningBox');
    interimBox.style.display = 'block'; interimBox.textContent = "Listening… (speak now)";

    const transcript = await startSpeechRecognition({ lang:'en-US', interim:true, timeout:9000, onInterim:(t)=>{ interimBox.textContent = "Listening… " + t; } });

    interimBox.textContent = ''; interimBox.style.display = 'none';

    if (!transcript) {
      log("No transcript received");
      if (!userGesturePerformed && tries === 1) {
        announce("I could not access the microphone automatically. If you allow microphone access, press the Voice Destination button once. Then speak after the beep.", false);
        voiceDestBtn.classList.add('secondary');
        await sleep(1500);
        continue;
      }
      announce("I didn't catch that. Let's try again.", false);
      continue;
    }

    log("Recognized destination: " + transcript);
    const candidates = Object.keys(node_coords); // allow all candidates (no currentLocation required)
    const bestMatch = findBestLocationMatch(transcript, candidates);
    if (!bestMatch) { announce(`I couldn't find a location matching "${transcript}". Please say your destination again.`, false); continue; }

    // Confirm with yes/no
    announce(`Did you mean ${bestMatch}? Say yes or no.`, true);
    await sleep(600);

    let confirmAttempts = 0;
    const maxConfirmAttempts = 3;
    while (confirmAttempts < maxConfirmAttempts) {
      confirmAttempts++;
      const interimBox2 = document.getElementById('listeningBox'); interimBox2.style.display = 'block'; interimBox2.textContent = "Listening for yes or no...";
      const confirmation = await startSpeechRecognition({ lang:'en-US', interim:false, timeout:6000 });
      interimBox2.textContent = ''; interimBox2.style.display = 'none';
      if (!confirmation) {
        if (confirmAttempts >= maxConfirmAttempts) {
          announce("Voice confirmation failed. I'll set this as your destination.", false);
          finalDestination = bestMatch; navigationActive = true;
          // Start camera so we can detect current location afterwards
          await startCamera();
          return;
        }
        announce("I didn't hear you. Please say yes or no.", false);
        continue;
      }
      const verdict = interpretConfirmation(confirmation);
      log("Confirmation verdict: " + verdict + " (from: '" + confirmation + "')");
      if (verdict === 'yes') {
        finalDestination = bestMatch; navigationActive = true;
        announce(`Final destination set to ${finalDestination}. Now starting camera to detect your current location.`, true);
        await startCamera(); // start scanning for current location
        return;
      } else if (verdict === 'no') {
        announce("Okay, please say your destination again.", false);
        break;
      } else if (verdict === 'ambiguous') {
        announce("I heard both yes and no. Please say clearly: yes or no.", false);
        continue;
      } else {
        announce("I didn't understand. Please say yes or no clearly.", false);
        continue;
      }
    }
    if (confirmAttempts >= maxConfirmAttempts) announce("Having trouble with confirmation. Let's try the destination again.", false);
  }

  announce("Voice input failed repeatedly. Please use text input instead.", false);
  show_destination_modal();
}

/* Dijkstra pathfinding + helpers (unchanged) */
function dijkstra(gr, start, end) {
  const pq = new MinHeap(); pq.push({cost:0,node:start,path:[]}); const visited = new Set();
  while (!pq.empty()) {
    const item = pq.pop(); const {cost,node,path} = item;
    if (visited.has(node)) continue;
    const newPath = path.concat([node]); visited.add(node);
    if (node === end) return {path:newPath, cost};
    const neighbors = gr[node] || {};
    for (const nb in neighbors) if (!visited.has(nb)) pq.push({cost: cost + neighbors[nb], node: nb, path: newPath});
  }
  return {path:[], cost: Infinity};
}
class MinHeap { constructor(){ this.a = []; } push(x){ this.a.push(x); this._siftUp(); } pop(){ if(this.a.length===0) return null; const r=this.a[0]; const last=this.a.pop(); if(this.a.length) { this.a[0]=last; this._siftDown(); } return r; } empty(){ return this.a.length===0; } _siftUp(){ let i=this.a.length-1; while(i>0){ let p=Math.floor((i-1)/2); if(this.a[p].cost<=this.a[i].cost) break; [this.a[p],this.a[i]]=[this.a[i],this.a[p]]; i=p; } } _siftDown(){ let i=0; const n=this.a.length; while(true){ let l=i*2+1; let r=i*2+2; let smallest=i; if(l<n && this.a[l].cost < this.a[smallest].cost) smallest=l; if(r<n && this.a[r].cost < this.a[smallest].cost) smallest=r; if(smallest===i) break; [this.a[i],this.a[smallest]]=[this.a[smallest],this.a[i]]; i=smallest; } } }

function get_simple_direction(from_coords, to_coords) {
  const dx = to_coords[0] - from_coords[0]; const dy = to_coords[1] - from_coords[1];
  const angle = (Math.atan2(dy, dx) * 180 / Math.PI + 360) % 360;
  if (angle >= 315 || angle < 45) return "head east";
  if (angle >= 45 && angle < 135) return "head south";
  if (angle >= 135 && angle < 225) return "head west";
  return "head north";
}

/* start_navigation: when currentLocation is known we can compute the path and start giving steps */
function start_navigation(destination) {
  if (!currentLocation) { announce("No current location. Scan QR codes first.", false); return; }
  if (!destination) { announce("No destination selected.", false); return; }

  finalDestination = destination;
  navigationActive = true;
  navigationStarted = true;
  window.destinationNode = destination;

  const res = dijkstra(graph, currentLocation, destination);
  if (!res.path.length || res.cost === Infinity) { announce("No path found to that destination.", false); return; }

  announce(`Navigation started to ${destination}. Total distance ${Math.round(res.cost)} meters. This is your final destination.`, true);
  drawMap();
  navigationDialog(res.path, res.cost);
}

/* navigationDialog simplified for VI users — give clear step messages and listen for 'next' or 'stop' */
function navigationDialog(path, total_cost) {
  let idx = 0;
  currentNavigationTarget = path[path.length - 1];

  function showStep() {
    if (idx >= path.length - 1) {
      const finalDest = path[path.length - 1];
      const finalText = `Final step: You are approaching ${finalDest}. Look for the QR code to confirm arrival.`;
      TTS.speak(finalText, true);
      overlayText.textContent = `Final: Approaching ${finalDest}`;
      log(`📍 Final step: Approaching ${finalDest}`);
      // START scanning to confirm arrival
      announce("I will now start the camera to scan for your arrival confirmation.", false);
      // small delay to allow announcement to finish then start camera
      setTimeout(()=>{ if (!scannerRunning) startCamera(); }, 900);
      return;
    }

    const current = path[idx];
    const next = path[idx + 1];
    const distance = (graph[current] && graph[current][next]) ? graph[current][next] : 0;
    let instruction;
    if (idx === 0 && node_coords[current] && node_coords[next]) {
      const direction = get_simple_direction(node_coords[current], node_coords[next]);
      instruction = `From ${current}, ${direction} towards ${next}`;
    } else { instruction = `Continue to ${next}`; }
    const stepInfo = `${instruction}. Distance: ${distance.toFixed(0)} meters.`;
    // speak stepInfo and then prompt VI-friendly controls
    TTS.speak(stepInfo, true);
    overlayText.textContent = `Step ${idx + 1}: ${instruction}`;
    log(`📍 Step ${idx + 1}/${path.length - 1}: ${stepInfo}`);
    // After step speech, prompt for voice command
    setTimeout(async () => {
      announce("Say 'next' for the next step, or 'stop' to cancel navigation.", false);
      const interimBox = document.getElementById('listeningBox'); interimBox.style.display = 'block'; interimBox.textContent = "Say 'next' or 'stop'...";
      const command = await startSpeechRecognition({ lang:'en-US', interim:false, timeout:10000 });
      interimBox.style.display = 'none'; interimBox.textContent = "";
      if (!command) {
        announce("No voice command heard. Continuing to next step.", false);
        idx++; setTimeout(showStep, 600); return;
      }
      const cmd = command.toLowerCase().trim();
      if (cmd.includes('stop') || cmd.includes('cancel') || cmd.includes('quit')) {
        TTS.speak("Navigation cancelled.", true);
        currentNavigationTarget = null; navigationActive = false; overlayText.textContent = "Navigation cancelled"; window.destinationNode = undefined; drawMap();
      } else {
        idx++; setTimeout(showStep, 600);
      }
    }, 900);
  }

  TTS.speak(`Beginning navigation to ${currentNavigationTarget}.`, true);
  setTimeout(showStep, 1000);
}

/* UI Event Handlers */
startBtn.onclick = async () => {
  if (scannerRunning) { announce("Scanner already running.", false); return; }
  userGesturePerformed = true;
  await startCamera();
};
stopBtn.onclick = () => { stopCamera(); };
restartBtn.onclick = () => { stopCamera(); foundResults.clear(); actionsTriggered=false; scanStartTime = Date.now(); setTimeout(()=>{ startBtn.click(); },300); };
voiceDestBtn.onclick = () => { userGesturePerformed = true; ask_destination_via_voice(); };
mapBtn.onclick = () => { drawMap(); mapModal.style.display = 'flex'; announce("Map opened. Close when ready.", false); };
closeMap.onclick = () => { mapModal.style.display = 'none'; announce("Map closed.", false); };

/* Keyboard shortcuts */
window.addEventListener('keydown', (e) => {
  if (e.key === 's' || e.key === 'S') { startBtn.click(); }
  if (e.key === 'v' || e.key === 'V') { voiceDestBtn.click(); }
  if (e.key === 'm' || e.key === 'M') { mapBtn.click(); }
  if (e.key === 'r' || e.key === 'R') { restartBtn.click(); }
  if (e.code === 'Space') { e.preventDefault(); stopBtn.click(); }
});

/* OpenCV initialization */
function onOpenCvReady(){ cvReady = true; backendLog("OpenCV runtime ready"); }
if (typeof cv !== 'undefined') {
  if (cv && cv.Mat) onOpenCvReady();
  else cv['onRuntimeInitialized'] = onOpenCvReady;
} else {
  setTimeout(()=>{ if (!cvReady) backendLog("OpenCV not loaded. Falling back to JS color detection."); },7000);
}

/* Cleanup */
window.addEventListener('beforeunload', () => { if (stream) stream.getTracks().forEach(t=>t.stop()); try{ speechSynthesis.cancel(); }catch(e){} });

/* INITIAL FLOW: ask destination first (voice if available), then start camera to detect current location */
(async function initialFlow(){
  // Wait shortly so UI renders and TTS voices load
  await sleep(600);
  if (SR_AVAILABLE) {
    // ask via voice
    ask_destination_via_voice().catch(e=>{ console.warn("ask_destination_via_voice error", e); show_destination_modal(); });
  } else {
    // fallback to modal selection
    show_destination_modal();
  }
})();

/* Initial logging */
log("App initialized. Speech recognition available: " + (SR_AVAILABLE ? 'yes' : 'no'));
log("Flow: Destination requested first; camera used to detect current location afterward.");
</script>
</body>
</html>
