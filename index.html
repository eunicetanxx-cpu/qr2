<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>VI-Friendly Indoor Navigation (Color QR + Obstacle Alerts)</title>
  <style>
    :root{
      --bg:#000; --card:#0b1220; --accent:#ffd54f; --accent-2:#00e676; --text:#fff;
      --muted:#9aa8b2;
      --btn-h:64px; --btn-font:20px;
    }
    html,body{height:100%; margin:0; background:linear-gradient(180deg,#05070a 0%, #0b0f14 100%); color:var(--text); font-family: system-ui, -apple-system, "Segoe UI", Roboto, Arial; -webkit-font-smoothing:antialiased;}
    .app {
      max-width: 980px;
      margin: 12px auto;
      padding: 18px;
      padding-bottom: 200px;
      background: linear-gradient(180deg, #071018 0, #07121a 100%);
      border-radius: 14px;
      box-shadow: 0 8px 36px rgba(0,0,0,0.6);
      border: 1px solid rgba(255,255,255,0.02);
    }
    header { display:flex; gap:12px; align-items:center; }
    h1 { font-size:24px; margin:0; color:var(--accent); letter-spacing:0.6px; }
    .subtitle { color: var(--muted); font-size:14px; margin-top:4px; }

    .controls { margin:14px 0; display:flex; gap:12px; flex-wrap:wrap; align-items:center; }
    .btn { background:var(--accent); color:#000; border:none; padding:12px 18px; border-radius:12px; font-size:var(--btn-font); height:var(--btn-h); min-width:150px; cursor:pointer; box-shadow:0 8px 18px rgba(0,0,0,0.5); }
    .btn.secondary { background:transparent; color:var(--text); border:2px solid rgba(255,255,255,0.06); }
    .btn.ghost { background:transparent; color:var(--accent); border:2px dashed rgba(255,213,79,0.18); }
    .btn:focus { outline:4px solid rgba(255,213,79,0.25); outline-offset:3px; }
    .select { font-size:18px; padding:12px; border-radius:12px; height:var(--btn-h); background:#07141a; color:var(--text); border:1px solid rgba(255,255,255,0.03); min-width:140px; }
    .btn.green { background:#4caf50; color:#fff; }
    .btn.red { background:#f44336; color:#fff; }
    .btn.yellow { background:#ffeb3b; color:#000; }
    .btn.grey { background:#9e9e9e; color:#fff; }

    .main-controls {
      bottom: 0;
      left: 0;
      right: 0;
      background: #071018;
      padding: 14px;
      display: flex;
      flex-direction: column;
      gap: 12px;
      z-index: 1000;
      box-shadow: 0 -4px 12px rgba(0,0,0,0.6);
    }
    .main-controls .controls-row { display: flex; justify-content: space-between; gap: 12px; }
    .main-controls .controls-row:last-child { justify-content: center; }

    .statusBox { margin-top:12px; padding:14px; background:linear-gradient(180deg,#071018,#06121a); border-radius:12px; border:1px solid rgba(0,255,136,0.03); min-height:100px; display:flex; gap:12px; align-items:flex-start; }
    #leftStatus { flex:1; }
    #overlayText { font-weight:800; font-size:20px; color:var(--text); margin-bottom:6px; }
    #srAnnounce { font-size:17px; color:var(--muted); margin-top:6px; }
    #listeningBox { margin-top:10px; font-size:18px; color:#ffb74d; min-height:22px; }

    .scan-progress { margin-top:10px; display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    .progress-pill { padding:10px 14px; border-radius:999px; background:#071018; color:var(--muted); font-size:18px; border:1px solid rgba(255,255,255,0.02); min-width:200px; text-align:center; }
    .progress-pill.found { background:var(--accent-2); color:#000; font-weight:800; border:2px solid rgba(0,64,0,0.7); }

    #previewWrap { display:flex; gap:12px; margin-top:14px; align-items:flex-start; justify-content:center; }
    #previewCanvas {
      width: 100%;
      max-width: 900px;
      height: auto;
      aspect-ratio: 4 / 3;
      background: #000;
      border-radius: 10px;
      border: 2px solid #0b1b2a;
      object-fit: cover;
      display:block;
    }

    .alerts { padding:12px; border-radius:10px; background:#061217; border:1px solid rgba(255,255,255,0.02); min-height:100px; color:var(--muted); }
    .alerts h4 { margin:0 0 6px 0; color:var(--accent); font-size:16px; }
    .alerts ul { margin:0; padding-left:18px; font-size:16px; color:var(--muted); }
    .alerts li { margin-bottom:6px; }

    #log { margin-top:12px; background:#02060a; color:#b8d3de; padding:12px; border-radius:10px; height:160px; overflow:auto; font-size:14px; border:1px solid rgba(255,255,255,0.02); }

    .map-modal { position:fixed; inset:0; display:none; align-items:center; justify-content:center; background:rgba(0,0,0,0.75); z-index:999; }
    .map-modal .box { background:#071018; padding:14px; max-width:900px; width:95%; max-height:85%; overflow:auto; border-radius:10px; border:2px solid rgba(255,255,255,0.02); color:#fff; }
    #mapCanvas { width:100%; height:auto; border-radius:6px; background:#fff; display:block; }

    footer { margin-top:14px; color:var(--muted); font-size:13px; text-align:center; }

    .visually-hidden { position:absolute !important; height:1px; width:1px; overflow:hidden; clip:rect(1px,1px,1px,1px); white-space:nowrap; }
    @media (max-width:760px){
      #previewCanvas { width:100%; height:260px; }
      .controls { gap:8px; }
      .btn { min-width:120px; font-size:18px; height:56px; }
    }
  </style>

  <!-- libs -->
  <script src="https://cdn.jsdelivr.net/npm/jsqr@1.4.0/dist/jsQR.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <div class="app" role="application" aria-labelledby="appTitle">
    <header>
      <div>
        <h1 id="appTitle">VI Indoor Navigation</h1>
        <div class="subtitle">Color QR navigation • Voice-first • Obstacle alerts</div>
      </div>
    </header>

   <div class="controls" role="region" aria-label="Settings">
    <select id="colorFilter" class="select" aria-label="Filter QR color. Choose Any, Red, Green or Blue">
      <option>Any</option><option>Red</option><option>Green</option><option>Blue</option>
    </select>

    <label style="display:flex; align-items:center; gap:8px; margin-left:6px; color:var(--muted); font-size:16px;">
      <input type="checkbox" id="enableDetect" checked aria-label="Enable object detection"> Enable Object Detection
    </label>
   </div>

   <div class="statusBox" role="status" aria-live="polite">
    <div id="leftStatus">
      <div id="overlayText">Ready — Start Scan to begin. Voice input will be started automatically when needed.</div>
      <div id="srAnnounce" aria-live="polite" role="log">Status messages will be read aloud.</div>
      <div id="listeningBox" aria-hidden="true"></div>
      <div class="scan-progress" aria-hidden="false">
        <div id="progressRed" class="progress-pill" role="status">Red QR: Not found</div>
        <div id="progressGreen" class="progress-pill" role="status">Green QR: Not found</div>
        <div id="progressBlue" class="progress-pill" role="status">Blue QR: Not found</div>
      </div>
    </div>

    <div id="alertsPanel">
      <div class="alerts" aria-live="polite">
        <h4>Object Alerts</h4>
        <ul id="alertsList"><li>No recent alerts</li></ul>
      </div>
    </div>
   </div>

   <div id="previewWrap">
     <canvas id="previewCanvas" width="800" height="600" aria-label="Camera preview for sighted helper"></canvas>
   </div>

   <div id="log" aria-live="polite" role="log"></div>

   <div class="map-modal" id="mapModal" role="dialog" aria-modal="true" aria-labelledby="mapTitle">
     <div class="box">
       <h3 id="mapTitle">Map Preview</h3>
       <canvas id="mapCanvas" width="900" height="600"></canvas>
       <div style="text-align:right; margin-top:8px;">
         <button id="closeMap" class="btn secondary" aria-label="Close map">Close</button>
       </div>
     </div>
   </div>

   <div class="controls main-controls" role="region" aria-label="Main controls">
     <div class="controls-row">
       <button id="startBtn" class="btn green" aria-pressed="false" aria-label="Start scanning for QR codes (S)">Start Scan</button>
       <button id="stopBtn" class="btn red" aria-pressed="false" aria-label="Stop scanning (Space)">Stop Scan</button>
       <button id="voiceDestBtn" class="btn yellow" aria-label="Voice destination input (V)">Voice Destination</button>
     </div>

     <div class="controls-row">
       <button id="restartBtn" class="btn grey" aria-label="Restart scanner (R)">Restart</button>
       <button id="mapBtn" class="btn grey" aria-label="Show map (M)">Show Map</button>
     </div>
   </div>

   <footer>Built for visually impaired users — spoken prompts, vibration and object alerts help navigation.</footer>
  </div>

<script>
/* ---------------------------
   small helpers & DOM
   --------------------------- */
const overlayText = document.getElementById('overlayText');
const srAnnounce = document.getElementById('srAnnounce');
const previewCanvas = document.getElementById('previewCanvas');
const previewCtx = previewCanvas.getContext('2d', { willReadFrequently: true });
const canvasDisp = document.createElement('canvas');
const ctxDisp = canvasDisp.getContext('2d', { willReadFrequently: true });
const logEl = document.getElementById('log');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const voiceDestBtn = document.getElementById('voiceDestBtn');
const colorFilterEl = document.getElementById('colorFilter');
const mapBtn = document.getElementById('mapBtn');
const mapModal = document.getElementById('mapModal');
const mapCanvas = document.getElementById('mapCanvas');
const closeMap = document.getElementById('closeMap');
const restartBtn = document.getElementById('restartBtn');
const progressRed = document.getElementById('progressRed');
const progressGreen = document.getElementById('progressGreen');
const progressBlue = document.getElementById('progressBlue');
const enableDetectCheckbox = document.getElementById('enableDetect');
const alertsList = document.getElementById('alertsList');

const log = (m) => { console.log(m); const t = new Date().toLocaleTimeString(); logEl.innerText += `[${t}] ${m}\n`; logEl.scrollTop = logEl.scrollHeight; };

/* ---------------------------
   state
   --------------------------- */
const SCAN_SIZE = 360;
let scanBox = { x: 0, y: 0, size: SCAN_SIZE };
let cvReady = false, animationFrameId = null, stream = null, scannerRunning = false;
let foundResults = new Map(), scanStartTime = Date.now(), currentLocation = null, currentNavigationTarget = null;
let latestDetections = [], actionsTriggered = false;

let cocoModel = null, cocoReady = false;
const DETECTION_INTERVAL_MS = 900, SCORE_THRESHOLD = 0.45, CENTER_TOLERANCE = 0.25;
const DISTANCE_ESTIMATE_SCALE = 1.6; let lastDetectTime = 0;
const alertCooldown = 3000; const lastAlertAt = {};
const HARMFUL_CLASSES = new Set(['person','chair','couch','bench','dining table','stop sign','tv','suitcase','backpack','bed','toilet']);

let userGesturePerformed = false;

/* ---------------------------
   TTS simple queue
   --------------------------- */
const TTS = {
  queue: [], speaking: false,
  speak(text, interrupt=false) {
    if(!text) return;
    if(interrupt){ this.queue=[]; if (speechSynthesis.speaking) speechSynthesis.cancel(); }
    this.queue.push(text); this._maybeSpeak();
  },
  _maybeSpeak() {
    if(this.speaking) return;
    const next = this.queue.shift();
    if(!next) return;
    this.speaking = true;
    const utt = new SpeechSynthesisUtterance(next); utt.rate = 1.0;
    utt.onend = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    utt.onerror = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    speechSynthesis.speak(utt);
  }
};
function announce(text, interrupt=false) {
  overlayText.textContent = text;
  srAnnounce.textContent = text;
  TTS.speak(text, interrupt);
  log(`[ANNOUNCE] ${text}`);
}

/* ---------------------------
   Speech recognition availability
   --------------------------- */
let SR_AVAILABLE = false;
try { const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition; if (SpeechRecognition) SR_AVAILABLE = true; } catch(e){ SR_AVAILABLE=false; }

/* ---------------------------
   Color processing & QR detection (omitted here for brevity)
   --------------------------- */
/* ... (all your existing color detection / OpenCV / QR code functions are assumed unchanged here)
   For brevity in this pasted example I keep them as in your original code above.
   In your actual file these functions must remain (createColorMask, extractColorChannel, etc.)
*/

/* For this message, the important changes are in the speech confirmation flow below.
   I will re-include only the speech-related functions and navigation-related functions
   that were adjusted so you can see the exact changes. */

/* ---------------------------
   Simple utilities for destination confirmation interpretation
   --------------------------- */
function interpretConfirmation(text, candidates=[]) {
  // return { intent: 'yes'|'no'|'new'|'unknown', matchedCandidate: string|null, raw: text }
  if (!text) return { intent: 'unknown', matchedCandidate: null, raw: text };
  const s = text.toLowerCase();
  const yesWords = ['yes','yeah','yep','correct','affirmative','sure','ok','okay','confirm','confirming','go ahead','go on','do it','please'];
  const noWords = ['no','nope','nah',"don't",'dont','not','negative','cancel','stop','incorrect','wrong','don’t'];
  // 1) direct yes/no tokens
  for (const w of yesWords) if (s.includes(w)) return { intent: 'yes', matchedCandidate: null, raw: text };
  for (const w of noWords) if (s.includes(w)) return { intent: 'no', matchedCandidate: null, raw: text };

  // 2) maybe user said a new destination name: check each candidate
  for (const c of candidates) {
    const cn = c.toLowerCase();
    if (s.includes(cn) || cn.includes(s) || s.split(' ').some(tok => cn.includes(tok) || tok.includes(cn))) {
      return { intent: 'new', matchedCandidate: c, raw: text };
    }
  }

  // 3) unknown fallback
  return { intent: 'unknown', matchedCandidate: null, raw: text };
}

/* ---------------------------
   Speech recognition helper (unchanged)
   --------------------------- */
function startSpeechRecognition({lang='en-US', interim=true, timeout=9000, onInterim=null} = {}) {
  return new Promise((resolve) => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) { resolve(null); return; }
    let recognition;
    try { recognition = new SR(); } catch(e) { resolve(null); return; }
    recognition.lang = lang; recognition.interimResults = interim; recognition.maxAlternatives = 3;
    let finalTranscript = '';
    let resolved = false;
    const timer = setTimeout(() => {
      if (!resolved) { resolved = true; try { recognition.stop(); } catch(e){}; resolve(null); }
    }, timeout);
    recognition.onresult = (evt) => {
      const results = Array.from(evt.results);
      const interimText = results.map(r => r[0].transcript).join(' ');
      if (onInterim) onInterim(interimText);
      for (const r of results) { if (r.isFinal) finalTranscript = r[0].transcript; }
      if (finalTranscript && !resolved) { resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(e){}; resolve(finalTranscript.trim()); }
    };
    recognition.onend = () => {
      if (resolved) return;
      resolved = true; clearTimeout(timer); resolve(finalTranscript ? finalTranscript.trim() : null);
    };
    recognition.onerror = (e) => {
      if (resolved) return;
      resolved = true; clearTimeout(timer); try { recognition.stop(); } catch(err){}; resolve(null);
    };
    try { recognition.start(); } catch(e) { clearTimeout(timer); resolve(null); }
  });
}

/* ---------------------------
   ask_destination_via_voice (FIXED confirmation flow)
   - Only starts navigation after explicit 'yes' or OK in fallback confirm.
   - If user says 'no' -> re-ask for destination.
   - If user replies with another location name during confirmation -> treat as new candidate and re-confirm.
*/
async function ask_destination_via_voice(){
  if (!currentLocation) { announce("No current location. Scan first.", false); return; }
  if (!SR_AVAILABLE) { announce("Speech recognition not available. Please use text input.", false); show_destination_modal(); return; }

  const candidates = Object.keys(node_coords).filter(n => n !== currentLocation);
  if (!candidates.length) { announce("No destinations available.", false); return; }

  let tries = 0;
  while (tries < 6) { // allow a few more tries
    tries++;
    announce("Please say your destination after the beep.", true);
    await new Promise(r=>setTimeout(r,700));
    const interimBox = document.getElementById('listeningBox');
    interimBox.style.display = 'block';
    interimBox.textContent = "Listening… (speak now)";
    const transcript = await startSpeechRecognition({
      lang: 'en-US',
      interim: true,
      timeout: 9000,
      onInterim: (t) => { interimBox.textContent = "Listening… " + t; }
    });
    interimBox.textContent = '';
    if (!transcript) {
      log("No transcript for destination (attempt " + tries + ")");
      if (!userGesturePerformed && tries === 1) {
        announce("I could not access the microphone automatically. If you allow microphone access, press the Voice Destination button once. Then speak after the beep.", false);
        voiceDestBtn.classList.add('secondary');
        await new Promise(r=>setTimeout(r,1500));
      } else {
        announce("I didn't catch that. Let's try again.", false);
      }
      continue;
    }

    log("Recognized destination phrase: " + transcript);
    const bestMatch = findBestLocationMatch(transcript, candidates);
    if (!bestMatch) {
      announce("I couldn't find that location. Please say your destination again.", false);
      continue; // ask again
    }

    // Now confirm: loop until explicit yes/no/new
    let confirmed = false;
    let confirmTries = 0;
    let candidate = bestMatch;

    while (!confirmed && confirmTries < 4) {
      confirmTries++;
      announce(`Did you mean ${candidate}? Say yes or no.`, false);
      await new Promise(r=>setTimeout(r,600));
      const conf = await startSpeechRecognition({lang:'en-US', interim:false, timeout:6000});
      if (!conf) {
        // fallback: browser confirm dialog (accessible)
        const ok = confirm(`Did you mean ${candidate}? Press OK for yes, Cancel for no.`);
        if (ok) {
          // explicit OK -> navigate
          start_navigation(candidate);
          return;
        } else {
          // explicit Cancel -> re-ask whole destination speech loop
          announce("Okay, let's try again.", false);
          break;
        }
      }

      const parsed = interpretConfirmation(conf, candidates);
      log("Confirmation recognized: '" + conf + "' -> intent: " + parsed.intent + (parsed.matchedCandidate ? " newCandidate:" + parsed.matchedCandidate : ""));
      if (parsed.intent === 'yes') {
        // Good — explicit yes
        start_navigation(candidate);
        return;
      } else if (parsed.intent === 'no') {
        // explicit no -> ask for destination again
        announce("Okay, please say your destination again.", false);
        break; // break confirmation loop, continue outer loop to re-ask destination
      } else if (parsed.intent === 'new' && parsed.matchedCandidate) {
        // user said a different location while confirming; update candidate and re-confirm
        candidate = parsed.matchedCandidate;
        announce(`Okay, did you mean ${candidate}?`, false);
        // loop again to confirm new candidate
        continue;
      } else {
        // unknown reply — ask to repeat or clarify
        announce("I didn't understand. Please say yes to confirm, or say no to try again.", false);
        // small delay then retry confirmation
        await new Promise(r=>setTimeout(r,600));
        continue;
      }
    } // end confirmation loop

    // If we reach here, either user said 'no' (we broke) or confirmation failed -> loop outer for another destination attempt
    continue;
  }

  // if we run out of tries
  announce("Voice input failed repeatedly. Please type destination instead.", false);
  show_destination_modal();
}

/* ---------------------------
   findBestLocationMatch (keeps your fuzzy matching)
*/
function findBestLocationMatch(input, candidates) {
  const s = input.toLowerCase().trim();
  let m = candidates.find(c=>c.toLowerCase()===s);
  if (m) return m;
  m = candidates.find(c=>c.toLowerCase().includes(s));
  if (m) return m;
  m = candidates.find(c=>c.toLowerCase().split(' ').some(word => s.includes(word) || word.includes(s)));
  if (m) return m;
  return null;
}

/* ---------------------------
   Navigation helpers (unchanged)
   - dijkstra, start_navigation, navigationDialog etc remain the same as before.
   For brevity I omit re-pasting them — keep your original implementations in the real file.
*/

/* ---------------------------
   UI wiring (unchanged)
*/
startBtn.onclick = async () => { if (scannerRunning) { announce("Scanner already running.", false); return; } userGesturePerformed = true; await startCamera(); };
stopBtn.onclick = () => { stopCamera(); };
restartBtn.onclick = () => { stopCamera(); foundResults.clear(); actionsTriggered=false; scanStartTime = Date.now(); setTimeout(()=>{ startBtn.click(); },300); };
voiceDestBtn.onclick = () => { userGesturePerformed = true; ask_destination_via_voice(); };
mapBtn.onclick = () => { drawMap(); mapModal.style.display = 'flex'; announce("Map opened. Close when ready.", false); };
closeMap.onclick = () => { mapModal.style.display = 'none'; announce("Map closed.", false); };

window.addEventListener('keydown', (e) => {
  if (e.key === 's' || e.key === 'S') { startBtn.click(); }
  if (e.key === 'v' || e.key === 'V') { voiceDestBtn.click(); }
  if (e.key === 'm' || e.key === 'M') { mapBtn.click(); }
  if (e.key === 'r' || e.key === 'R') { restartBtn.click(); }
  if (e.code === 'Space') { e.preventDefault(); stopBtn.click(); }
});

/* ---------------------------
   OpenCV init and other boot logs (unchanged)
*/
function onOpenCvReady(){ cvReady = true; log("OpenCV ready"); announce("OpenCV loaded - improved color detection available.", false); }
if (typeof cv !== 'undefined') {
  if (cv && cv.Mat) onOpenCvReady();
  else cv['onRuntimeInitialized'] = onOpenCvReady;
} else {
  setTimeout(()=>{ if (!cvReady) announce("OpenCV not loaded. Falling back to JS color detection.", false); }, 7000);
}

window.addEventListener('beforeunload', ()=>{ if (stream) stream.getTracks().forEach(t=>t.stop()); speechSynthesis.cancel(); });

announce("Ready. Start Scan to begin scanning for three color QR codes. The app will listen automatically when needed.", false);
log("App initialized. Speech recognition available: " + (SR_AVAILABLE ? 'yes' : 'no'));
log("Scan sequence: Red (location) + Green (map) + Blue (accessibility)");
</script>
</body>
</html>
